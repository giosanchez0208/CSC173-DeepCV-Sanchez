{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giosanchez0208/CSC173-DeepCV-Sanchez/blob/main/refine_segmentation_model_safe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a7e14ac",
      "metadata": {
        "id": "3a7e14ac"
      },
      "source": [
        "## Setup: Google Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "02620f41",
      "metadata": {
        "id": "02620f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e443be3-8aca-41b8-d7c0-57ddf7edd9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: Tesla T4\n",
            "Memory: 15.83 GB\n",
            "\n",
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA version: 12.6\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Verify CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    print(f'GPU available: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print('No GPU available, using CPU (training will be slow)')\n",
        "\n",
        "print(f'\\nPyTorch version: {torch.__version__}')\n",
        "print(f'CUDA version: {torch.version.cuda}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1b038eae",
      "metadata": {
        "id": "1b038eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfae8c1-cd55-4bfe-968c-0f5b1821deb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m134.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.8/121.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m784.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m635.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.5/348.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "cudf-polars-cu12 25.10.0 requires polars<1.33,>=1.28, but you have polars 1.36.1 which is incompatible.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mAll packages installed successfully\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q ultralytics opencv-python-headless pillow pyyaml numpy scipy matplotlib pandas gdown --force-reinstall\n",
        "\n",
        "print('All packages installed successfully')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb3737f",
      "metadata": {
        "id": "9cb3737f"
      },
      "source": [
        "## Dataset and Model Download (Reproducible Setup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0b48dbb1",
      "metadata": {
        "id": "0b48dbb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41e8fe0-0604-4dbe-b9c8-cefab3c88693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure created:\n",
            "  Root: /content/ocr_project\n",
            "  Dataset: /content/ocr_project/dataset\n",
            "  Models: /content/ocr_project/models\n",
            "  Checkpoints: /content/ocr_project/checkpoints\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "import zipfile\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Public Google Drive folder for the dataset\n",
        "PUBLIC_DRIVE_FOLDER = 'https://drive.google.com/drive/folders/1rYbZXSwnd0DQ49VP_04C8OYkhU6b4p-t'\n",
        "\n",
        "# File IDs (you'll need to extract these from the public folder)\n",
        "# You can get these by right-clicking on the file in Google Drive and getting the shareable link\n",
        "# The file ID is the long string between /d/ and /view\n",
        "DATASET_ZIP_ID = '1GKtBNb8FNBdLfc5QngCFhRqNB-XjcBId'  # Replace with actual file ID\n",
        "PRETRAINED_MODEL_ID = '1v8NkcQavobGCrAfYx7YnlYVH4nCpz6PZ'  # Replace with actual file ID\n",
        "\n",
        "# Local paths\n",
        "LOCAL_ROOT = '/content/ocr_project'\n",
        "DATASET_ZIP_PATH = f'{LOCAL_ROOT}/dataset.zip'\n",
        "LOCAL_DATASET_PATH = f'{LOCAL_ROOT}/dataset'\n",
        "LOCAL_MODELS_PATH = f'{LOCAL_ROOT}/models'\n",
        "LOCAL_CHECKPOINTS_PATH = f'{LOCAL_ROOT}/checkpoints'\n",
        "\n",
        "# Create directories\n",
        "for path in [LOCAL_ROOT, LOCAL_MODELS_PATH, LOCAL_CHECKPOINTS_PATH]:\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Directory structure created:')\n",
        "print(f'  Root: {LOCAL_ROOT}')\n",
        "print(f'  Dataset: {LOCAL_DATASET_PATH}')\n",
        "print(f'  Models: {LOCAL_MODELS_PATH}')\n",
        "print(f'  Checkpoints: {LOCAL_CHECKPOINTS_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b2cd3d33",
      "metadata": {
        "id": "b2cd3d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b219186-62d6-4c9a-cd82-0604451c58a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already exists at: /content/ocr_project/dataset.zip\n",
            "Pretrained model already exists at: /content/ocr_project/models/custom_ocr_last.pt\n"
          ]
        }
      ],
      "source": [
        "def download_file_from_drive(file_id, output_path, retries=3):\n",
        "    \"\"\"Download a file from Google Drive using gdown.\"\"\"\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            print(f'Download attempt {attempt + 1}/{retries} for {output_path}')\n",
        "            gdown.download(url, output_path, quiet=False)\n",
        "\n",
        "            if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
        "                print(f'Successfully downloaded: {output_path}')\n",
        "                print(f'File size: {os.path.getsize(output_path) / (1024**2):.2f} MB')\n",
        "                return True\n",
        "            else:\n",
        "                print(f'Download failed: file is empty or does not exist')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'Download attempt {attempt + 1} failed: {e}')\n",
        "\n",
        "    return False\n",
        "\n",
        "# Download dataset if not already present\n",
        "if not os.path.exists(DATASET_ZIP_PATH):\n",
        "    print('Downloading dataset...')\n",
        "    # IMPORTANT: Replace with actual file ID from your public folder\n",
        "    # You need to get the actual file ID for dataset.zip\n",
        "    success = download_file_from_drive(DATASET_ZIP_ID, DATASET_ZIP_PATH)\n",
        "    if not success:\n",
        "        print('ERROR: Failed to download dataset. Please check the file ID.')\n",
        "        print(f'Public folder: {PUBLIC_DRIVE_FOLDER}')\n",
        "        print('Please update DATASET_ZIP_ID with the actual file ID from the dataset.zip file')\n",
        "        raise FileNotFoundError('Dataset download failed')\n",
        "else:\n",
        "    print(f'Dataset already exists at: {DATASET_ZIP_PATH}')\n",
        "\n",
        "# Download pretrained model if not already present\n",
        "PRETRAINED_MODEL_PATH = f'{LOCAL_MODELS_PATH}/custom_ocr_last.pt'\n",
        "if not os.path.exists(PRETRAINED_MODEL_PATH):\n",
        "    print('\\nDownloading pretrained model...')\n",
        "    # IMPORTANT: Replace with actual file ID from your public folder\n",
        "    # You need to get the actual file ID for custom_ocr_last.pt\n",
        "    success = download_file_from_drive(PRETRAINED_MODEL_ID, PRETRAINED_MODEL_PATH)\n",
        "    if not success:\n",
        "        print('WARNING: Failed to download pretrained model. Training will start from scratch.')\n",
        "        PRETRAINED_MODEL_PATH = None\n",
        "else:\n",
        "    print(f'Pretrained model already exists at: {PRETRAINED_MODEL_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "7000dfec",
      "metadata": {
        "id": "7000dfec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d14da8-f9be-4806-a566-eb5daa2b4c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already extracted at: /content/ocr_project/dataset\n",
            "\n",
            "Data configuration: /content/ocr_project/dataset/data.yaml\n",
            "Pretrained model: /content/ocr_project/models/custom_ocr_last.pt\n"
          ]
        }
      ],
      "source": [
        "# Extract dataset if not already extracted\n",
        "if not os.path.exists(LOCAL_DATASET_PATH) or not os.path.exists(f'{LOCAL_DATASET_PATH}/data.yaml'):\n",
        "    print('\\nExtracting dataset...')\n",
        "\n",
        "    if not os.path.exists(DATASET_ZIP_PATH):\n",
        "        print(f'ERROR: Dataset zip not found at {DATASET_ZIP_PATH}')\n",
        "        raise FileNotFoundError('Dataset zip file not found')\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(DATASET_ZIP_PATH, 'r') as zip_ref:\n",
        "            zip_ref.extractall(LOCAL_ROOT)\n",
        "\n",
        "        # Check if extraction created a nested 'dataset' folder\n",
        "        extracted_paths = list(Path(LOCAL_ROOT).glob('**/data.yaml'))\n",
        "\n",
        "        if extracted_paths:\n",
        "            # Found data.yaml somewhere\n",
        "            data_yaml_path = str(extracted_paths[0])\n",
        "            dataset_parent = str(extracted_paths[0].parent)\n",
        "\n",
        "            # If it's not in the expected location, move it\n",
        "            if dataset_parent != LOCAL_DATASET_PATH:\n",
        "                print(f'Moving dataset from {dataset_parent} to {LOCAL_DATASET_PATH}')\n",
        "                if os.path.exists(LOCAL_DATASET_PATH):\n",
        "                    shutil.rmtree(LOCAL_DATASET_PATH)\n",
        "                shutil.move(dataset_parent, LOCAL_DATASET_PATH)\n",
        "\n",
        "        print(f'Dataset extracted to: {LOCAL_DATASET_PATH}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'ERROR: Failed to extract dataset: {e}')\n",
        "        raise\n",
        "else:\n",
        "    print(f'Dataset already extracted at: {LOCAL_DATASET_PATH}')\n",
        "\n",
        "# Verify data.yaml exists\n",
        "DATA_YAML_PATH = f'{LOCAL_DATASET_PATH}/data.yaml'\n",
        "if not os.path.exists(DATA_YAML_PATH):\n",
        "    print(f'ERROR: data.yaml not found at {DATA_YAML_PATH}')\n",
        "    print('Looking for data.yaml in extracted files...')\n",
        "\n",
        "    # Search for data.yaml\n",
        "    for root, dirs, files in os.walk(LOCAL_ROOT):\n",
        "        if 'data.yaml' in files:\n",
        "            DATA_YAML_PATH = os.path.join(root, 'data.yaml')\n",
        "            print(f'Found data.yaml at: {DATA_YAML_PATH}')\n",
        "            break\n",
        "\n",
        "    if not os.path.exists(DATA_YAML_PATH):\n",
        "        raise FileNotFoundError(f'data.yaml not found in {LOCAL_ROOT}')\n",
        "\n",
        "print(f'\\nData configuration: {DATA_YAML_PATH}')\n",
        "print(f'Pretrained model: {PRETRAINED_MODEL_PATH if PRETRAINED_MODEL_PATH else \"None (starting from scratch)\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "0ebec263",
      "metadata": {
        "id": "0ebec263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5c7345-dacb-42d0-e8d4-e72c4680e03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DATASET SANITY CHECK ===\n",
            "✓ train/images: 15960 files\n",
            "✓ train/labels: 15960 files\n",
            "✓ val/images: 2000 files\n",
            "✓ val/labels: 2000 files\n",
            "✓ test/images: 2000 files\n",
            "✓ test/labels: 2000 files\n",
            "\n",
            "data.yaml content:\n",
            "  Classes: 36\n",
            "  Path: /content/ocr_project/dataset\n",
            "  Train: train/images\n",
            "  Val: val/images\n",
            "\n",
            "✓ All dataset checks passed\n"
          ]
        }
      ],
      "source": [
        "# Sanity check: Verify dataset structure\n",
        "print('\\n=== DATASET SANITY CHECK ===')\n",
        "\n",
        "required_folders = ['train/images', 'train/labels',\n",
        "                    'val/images', 'val/labels',\n",
        "                    'test/images', 'test/labels']\n",
        "\n",
        "all_good = True\n",
        "for folder in required_folders:\n",
        "    folder_path = f'{LOCAL_DATASET_PATH}/{folder}'\n",
        "    if os.path.exists(folder_path):\n",
        "        file_count = len(os.listdir(folder_path))\n",
        "        print(f'✓ {folder}: {file_count} files')\n",
        "    else:\n",
        "        print(f'✗ {folder}: NOT FOUND')\n",
        "        all_good = False\n",
        "\n",
        "# Check data.yaml content\n",
        "try:\n",
        "    with open(DATA_YAML_PATH, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "\n",
        "    print(f'\\ndata.yaml content:')\n",
        "    print(f'  Classes: {len(data_config.get(\"names\", []))}')\n",
        "    print(f'  Path: {data_config.get(\"path\", \"Not specified\")}')\n",
        "    print(f'  Train: {data_config.get(\"train\", \"Not specified\")}')\n",
        "    print(f'  Val: {data_config.get(\"val\", \"Not specified\")}')\n",
        "\n",
        "    # Fix paths in data.yaml if they're wrong\n",
        "    if data_config.get('path') != LOCAL_DATASET_PATH:\n",
        "        print(f'\\nFixing data.yaml paths...')\n",
        "        data_config['path'] = LOCAL_DATASET_PATH\n",
        "        data_config['train'] = 'train/images'\n",
        "        data_config['val'] = 'val/images'\n",
        "        data_config['test'] = 'test/images'\n",
        "\n",
        "        with open(DATA_YAML_PATH, 'w') as f:\n",
        "            yaml.dump(data_config, f, default_flow_style=False)\n",
        "        print(f'  Updated paths in data.yaml')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'ERROR reading data.yaml: {e}')\n",
        "    all_good = False\n",
        "\n",
        "if all_good:\n",
        "    print('\\n✓ All dataset checks passed')\n",
        "else:\n",
        "    print('\\n✗ Dataset has issues. Please check the structure.')\n",
        "    raise ValueError('Dataset structure is incorrect')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6201797b",
      "metadata": {
        "id": "6201797b"
      },
      "source": [
        "## Enhanced Checkpoint Management System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "e4287274",
      "metadata": {
        "id": "e4287274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd30071e-f375-409b-a9aa-197424782e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint Manager initialized:\n",
            "  Experiment: refine_20251222_155732\n",
            "  Local directory: /content/ocr_project/checkpoints/refine_20251222_155732\n",
            "\n",
            "Checkpoint system ready. CSV will be saved every epoch.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import threading\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "class CheckpointManager:\n",
        "    \"\"\"\n",
        "    Robust checkpoint management system that:\n",
        "    1. Saves CSV progress every epoch\n",
        "    2. Saves model checkpoints to Google Drive every epoch\n",
        "    3. Maintains detailed training history\n",
        "    4. Allows resuming from any point\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, experiment_name, local_checkpoint_dir, drive_checkpoint_dir=None):\n",
        "        \"\"\"\n",
        "        Initialize checkpoint manager.\n",
        "\n",
        "        Args:\n",
        "            experiment_name: Name for this training run\n",
        "            local_checkpoint_dir: Local directory for fast checkpoint access\n",
        "            drive_checkpoint_dir: Google Drive directory for permanent storage (optional)\n",
        "        \"\"\"\n",
        "        self.experiment_name = experiment_name\n",
        "        self.local_dir = Path(local_checkpoint_dir) / experiment_name\n",
        "        self.drive_dir = Path(drive_checkpoint_dir) / experiment_name if drive_checkpoint_dir else None\n",
        "\n",
        "        # Create directories\n",
        "        self.local_dir.mkdir(parents=True, exist_ok=True)\n",
        "        if self.drive_dir:\n",
        "            self.drive_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # File paths\n",
        "        self.csv_path = self.local_dir / 'training_progress.csv'\n",
        "        self.config_path = self.local_dir / 'training_config.json'\n",
        "        self.best_model_local = self.local_dir / 'best_model.pt'\n",
        "        self.last_model_local = self.local_dir / 'last_model.pt'\n",
        "\n",
        "        if self.drive_dir:\n",
        "            self.best_model_drive = self.drive_dir / 'best_model.pt'\n",
        "            self.last_model_drive = self.drive_dir / 'last_model.pt'\n",
        "            self.csv_drive = self.drive_dir / 'training_progress.csv'\n",
        "\n",
        "        # Initialize CSV if it doesn't exist\n",
        "        self._initialize_csv()\n",
        "\n",
        "        print(f'Checkpoint Manager initialized:')\n",
        "        print(f'  Experiment: {experiment_name}')\n",
        "        print(f'  Local directory: {self.local_dir}')\n",
        "        if self.drive_dir:\n",
        "            print(f'  Drive directory: {self.drive_dir}')\n",
        "\n",
        "    def _initialize_csv(self):\n",
        "        \"\"\"Initialize CSV with required columns.\"\"\"\n",
        "        if not self.csv_path.exists():\n",
        "            columns = [\n",
        "                'epoch', 'timestamp',\n",
        "                'train/cls_loss', 'val/cls_loss',\n",
        "                'train/seg_loss', 'val/seg_loss',\n",
        "                'train/box_loss', 'val/box_loss',\n",
        "                'metrics/precision(M)', 'metrics/recall(M)',\n",
        "                'metrics/mAP50(M)', 'metrics/mAP50-95(M)',\n",
        "                'learning_rate', 'phase',\n",
        "                'ocr_char_accuracy', 'ocr_top2_accuracy', 'ocr_top3_accuracy'\n",
        "            ]\n",
        "            pd.DataFrame(columns=columns).to_csv(self.csv_path, index=False)\n",
        "\n",
        "    def save_config(self, config):\n",
        "        \"\"\"Save training configuration.\"\"\"\n",
        "        with open(self.config_path, 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        # Also save to drive if available\n",
        "        if self.drive_dir:\n",
        "            drive_config_path = self.drive_dir / 'training_config.json'\n",
        "            with open(drive_config_path, 'w') as f:\n",
        "                json.dump(config, f, indent=2)\n",
        "\n",
        "    def save_progress(self, epoch, metrics, model_path=None, is_best=False):\n",
        "        \"\"\"\n",
        "        Save training progress for an epoch.\n",
        "\n",
        "        Args:\n",
        "            epoch: Current epoch number\n",
        "            metrics: Dictionary of metrics\n",
        "            model_path: Path to model file to save\n",
        "            is_best: Whether this is the best model so far\n",
        "        \"\"\"\n",
        "        # Add epoch and timestamp to metrics\n",
        "        metrics['epoch'] = epoch\n",
        "        metrics['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        # Load existing CSV and append new row\n",
        "        df = pd.read_csv(self.csv_path) if self.csv_path.exists() else pd.DataFrame()\n",
        "        new_row = pd.DataFrame([metrics])\n",
        "        df = pd.concat([df, new_row], ignore_index=True)\n",
        "\n",
        "        # Save to local CSV\n",
        "        df.to_csv(self.csv_path, index=False)\n",
        "\n",
        "        # Save model if provided\n",
        "        if model_path and Path(model_path).exists():\n",
        "            # Save last model\n",
        "            shutil.copy2(model_path, self.last_model_local)\n",
        "\n",
        "            # Save best model if applicable\n",
        "            if is_best:\n",
        "                shutil.copy2(model_path, self.best_model_local)\n",
        "                print(f'  [Checkpoint] New best model saved (epoch {epoch})')\n",
        "\n",
        "            # Async save to Google Drive\n",
        "            if self.drive_dir:\n",
        "                self._async_save_to_drive(model_path, is_best)\n",
        "\n",
        "        # Async save CSV to Google Drive\n",
        "        if self.drive_dir:\n",
        "            self._async_save_csv_to_drive()\n",
        "\n",
        "        print(f'[Checkpoint] Progress saved for epoch {epoch}')\n",
        "\n",
        "    def _async_save_to_drive(self, model_path, is_best):\n",
        "        \"\"\"Asynchronously save model to Google Drive.\"\"\"\n",
        "        def save_task():\n",
        "            try:\n",
        "                # Save last model\n",
        "                shutil.copy2(model_path, self.last_model_drive)\n",
        "\n",
        "                # Save best model if applicable\n",
        "                if is_best:\n",
        "                    shutil.copy2(model_path, self.best_model_drive)\n",
        "\n",
        "                print(f'  [Checkpoint] Model backed up to Drive')\n",
        "            except Exception as e:\n",
        "                print(f'  [Checkpoint] Warning: Failed to save model to Drive: {e}')\n",
        "\n",
        "        # Start async save\n",
        "        thread = threading.Thread(target=save_task, daemon=True)\n",
        "        thread.start()\n",
        "\n",
        "    def _async_save_csv_to_drive(self):\n",
        "        \"\"\"Asynchronously save CSV to Google Drive.\"\"\"\n",
        "        def save_task():\n",
        "            try:\n",
        "                shutil.copy2(self.csv_path, self.csv_drive)\n",
        "            except Exception as e:\n",
        "                print(f'  [Checkpoint] Warning: Failed to save CSV to Drive: {e}')\n",
        "\n",
        "        thread = threading.Thread(target=save_task, daemon=True)\n",
        "        thread.start()\n",
        "\n",
        "    def get_last_checkpoint(self):\n",
        "        \"\"\"Get information about the last checkpoint.\"\"\"\n",
        "        info = {\n",
        "            'exists': False,\n",
        "            'last_epoch': 0,\n",
        "            'best_model_path': None,\n",
        "            'last_model_path': None\n",
        "        }\n",
        "\n",
        "        # Check local first\n",
        "        if self.csv_path.exists():\n",
        "            df = pd.read_csv(self.csv_path)\n",
        "            if len(df) > 0:\n",
        "                info['exists'] = True\n",
        "                info['last_epoch'] = int(df['epoch'].iloc[-1])\n",
        "\n",
        "                # Check for model files\n",
        "                if self.last_model_local.exists():\n",
        "                    info['last_model_path'] = str(self.last_model_local)\n",
        "                if self.best_model_local.exists():\n",
        "                    info['best_model_path'] = str(self.best_model_local)\n",
        "\n",
        "        return info\n",
        "\n",
        "    def load_progress(self):\n",
        "        \"\"\"Load training progress from CSV.\"\"\"\n",
        "        if self.csv_path.exists():\n",
        "            return pd.read_csv(self.csv_path)\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Initialize checkpoint manager\n",
        "experiment_name = f'refine_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
        "checkpoint_manager = CheckpointManager(\n",
        "    experiment_name=experiment_name,\n",
        "    local_checkpoint_dir=LOCAL_CHECKPOINTS_PATH,\n",
        "    drive_checkpoint_dir=None  # Will be set after mounting Drive\n",
        ")\n",
        "\n",
        "print('\\nCheckpoint system ready. CSV will be saved every epoch.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e25dad",
      "metadata": {
        "id": "c0e25dad"
      },
      "source": [
        "## Mount Google Drive for Permanent Storage (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4557780b",
      "metadata": {
        "id": "4557780b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e756278-9810-4871-d1c8-67358a614ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully\n",
            "Checkpoints will be saved to: /content/drive/MyDrive/ocr_checkpoints\n",
            "Training configuration saved\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive if available\n",
        "DRIVE_CHECKPOINT_DIR = None\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Set up Drive checkpoint directory\n",
        "    DRIVE_CHECKPOINT_DIR = f'/content/drive/MyDrive/ocr_checkpoints'\n",
        "    os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "    # Update checkpoint manager with Drive directory\n",
        "    checkpoint_manager.drive_dir = Path(DRIVE_CHECKPOINT_DIR) / experiment_name\n",
        "    checkpoint_manager.drive_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    checkpoint_manager.best_model_drive = checkpoint_manager.drive_dir / 'best_model.pt'\n",
        "    checkpoint_manager.last_model_drive = checkpoint_manager.drive_dir / 'last_model.pt'\n",
        "    checkpoint_manager.csv_drive = checkpoint_manager.drive_dir / 'training_progress.csv'\n",
        "\n",
        "    print(f'Google Drive mounted successfully')\n",
        "    print(f'Checkpoints will be saved to: {DRIVE_CHECKPOINT_DIR}')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'Note: Google Drive not mounted. Checkpoints will only be saved locally.')\n",
        "    print(f'Error: {e}')\n",
        "\n",
        "# Save training configuration\n",
        "training_config = {\n",
        "    'experiment_name': experiment_name,\n",
        "    'dataset_path': LOCAL_DATASET_PATH,\n",
        "    'pretrained_model': PRETRAINED_MODEL_PATH,\n",
        "    'data_yaml': DATA_YAML_PATH,\n",
        "    'device': device,\n",
        "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "}\n",
        "\n",
        "checkpoint_manager.save_config(training_config)\n",
        "print(f'Training configuration saved')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e25dad-2",
      "metadata": {
        "id": "c0e25dad-2"
      },
      "source": [
        "## Core Components (Reused from Original Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7000dfec-2",
      "metadata": {
        "id": "7000dfec-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74291757-e61b-4233-ce12-12e91d0d05d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 36\n",
            "Characters: ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\n",
            "Similarity matrix initialized: torch.Size([36, 36])\n"
          ]
        }
      ],
      "source": [
        "# Character set and similarity matrix (from original)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "CHARS = [chr(i) for i in range(65, 91)] + [str(i) for i in range(10)]\n",
        "NUM_CLASSES = len(CHARS)\n",
        "CHAR_TO_IDX = {c: i for i, c in enumerate(CHARS)}\n",
        "IDX_TO_CHAR = {i: c for i, c in enumerate(CHARS)}\n",
        "\n",
        "print(f'Number of classes: {NUM_CLASSES}')\n",
        "print(f'Characters: {\"\".join(CHARS)}')\n",
        "\n",
        "SIMILAR_GROUPS = [\n",
        "    ['O', '0'],\n",
        "    ['I', '1'],\n",
        "    ['S', '5'],\n",
        "    ['Z', '2'],\n",
        "    ['B', '8'],\n",
        "    ['D', '0'],\n",
        "    ['G', 'C'],\n",
        "    ['U', 'V'],\n",
        "    ['P', 'R'],\n",
        "]\n",
        "\n",
        "def create_similarity_matrix(num_classes=NUM_CLASSES, groups=SIMILAR_GROUPS, base_sim=0.6):\n",
        "    S = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
        "    np.fill_diagonal(S, 1.0)\n",
        "    for group in groups:\n",
        "        idxs = [CHAR_TO_IDX[c] for c in group if c in CHAR_TO_IDX]\n",
        "        for i in idxs:\n",
        "            for j in idxs:\n",
        "                if i != j:\n",
        "                    S[i, j] = base_sim\n",
        "    return torch.tensor(S, dtype=torch.float32)\n",
        "\n",
        "similarity_matrix = create_similarity_matrix()\n",
        "print(f'Similarity matrix initialized: {similarity_matrix.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "0ebec263-2",
      "metadata": {
        "id": "0ebec263-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc910fe5-4e4d-48bb-aca1-04bbdf5310de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined similarity-aware loss defined\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Similarity-Aware Loss with Adaptive Weighting\n",
        "class RefinedSimilarityAwareTopKLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Enhanced loss for fine-tuning with:\n",
        "    - Higher penalty for similar character confusion\n",
        "    - Adaptive temperature based on training phase\n",
        "    - Confidence-based weighting\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=NUM_CLASSES, similarity_matrix=None,\n",
        "                 k=3, initial_temperature=0.5, base_weight=0.5, topk_weight=0.5,\n",
        "                 epochs=40):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.k = k\n",
        "        self.initial_temperature = initial_temperature\n",
        "        self.base_weight = base_weight\n",
        "        self.topk_weight = topk_weight\n",
        "        self.epochs = epochs\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        if similarity_matrix is not None:\n",
        "            self.register_buffer('similarity_matrix', similarity_matrix)\n",
        "        else:\n",
        "            self.register_buffer('similarity_matrix', create_similarity_matrix())\n",
        "\n",
        "    def update_epoch(self, epoch):\n",
        "        \"\"\"Update current epoch for temperature annealing.\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "\n",
        "    def get_temperature(self):\n",
        "        \"\"\"Anneal temperature more aggressively for fine-tuning.\"\"\"\n",
        "        progress = self.current_epoch / max(self.epochs, 1)\n",
        "        # Start at 0.5, go to 0.3 (sharper predictions)\n",
        "        return max(0.3, self.initial_temperature - progress * 0.2)\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        B = logits.size(0)\n",
        "        device = logits.device\n",
        "\n",
        "        temperature = self.get_temperature()\n",
        "\n",
        "        # Standard cross-entropy\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "\n",
        "        # Softmax with temperature\n",
        "        probs = F.softmax(logits / temperature, dim=1)\n",
        "        topk_probs, topk_indices = torch.topk(probs, min(self.k, self.num_classes), dim=1)\n",
        "\n",
        "        # Similarity-aware penalty\n",
        "        sim_loss = torch.zeros(B, device=device)\n",
        "        confidence_scores = []\n",
        "\n",
        "        for i in range(B):\n",
        "            t = targets[i].item()\n",
        "            if t < 0 or t >= self.num_classes:\n",
        "                continue\n",
        "\n",
        "            sims = self.similarity_matrix[t][topk_indices[i]]\n",
        "\n",
        "            # Higher penalty for similar character confusion\n",
        "            penalties = (1.0 - sims) * 1.5  # Amplify penalty\n",
        "            weighted_penalties = topk_probs[i] * penalties\n",
        "            sim_loss[i] = weighted_penalties.sum()\n",
        "\n",
        "            confidence_scores.append(topk_probs[i][0].item())\n",
        "\n",
        "        if len(confidence_scores) == 0:\n",
        "            return ce_loss.mean()\n",
        "\n",
        "        # Adaptive weighting based on confidence\n",
        "        confidence = torch.tensor(confidence_scores, device=device)\n",
        "\n",
        "        # When confident: rely more on CE (trust the model)\n",
        "        # When uncertain: rely more on similarity (guide the model)\n",
        "        adaptive_base = self.base_weight + (1 - confidence) * 0.2\n",
        "        adaptive_topk = self.topk_weight + confidence * 0.2\n",
        "\n",
        "        # Normalize\n",
        "        total_weight = adaptive_base + adaptive_topk\n",
        "        adaptive_base = adaptive_base / total_weight\n",
        "        adaptive_topk = adaptive_topk / total_weight\n",
        "\n",
        "        total_loss = adaptive_base * ce_loss + adaptive_topk * sim_loss\n",
        "        return total_loss.mean()\n",
        "\n",
        "print('Refined similarity-aware loss defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4557780b-2",
      "metadata": {
        "id": "4557780b-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2dfab5-be23-4465-c5b0-a2ef32eac59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR metrics module loaded\n"
          ]
        }
      ],
      "source": [
        "# OCR Metrics (reused from original)\n",
        "class OCRMetrics:\n",
        "    \"\"\"Compute OCR-specific validation metrics.\"\"\"\n",
        "    def __init__(self, similarity_matrix=None):\n",
        "        self.similarity_matrix = similarity_matrix if similarity_matrix is not None else create_similarity_matrix()\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_chars = 0\n",
        "        self.correct_chars = 0\n",
        "        self.top2_correct = 0\n",
        "        self.top3_correct = 0\n",
        "        self.similarity_score = 0.0\n",
        "\n",
        "    def update(self, predictions, targets, top_k_preds=None):\n",
        "        predictions = predictions.cpu().numpy()\n",
        "        targets = targets.cpu().numpy()\n",
        "\n",
        "        self.total_chars += len(targets)\n",
        "        self.correct_chars += (predictions == targets).sum()\n",
        "\n",
        "        # Similarity-aware accuracy\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            if 0 <= target < len(self.similarity_matrix) and 0 <= pred < len(self.similarity_matrix):\n",
        "                sim = self.similarity_matrix[target][pred].item()\n",
        "                self.similarity_score += sim\n",
        "\n",
        "        # Top-k accuracy\n",
        "        if top_k_preds is not None:\n",
        "            top_k_preds = top_k_preds.cpu().numpy()\n",
        "            for i, target in enumerate(targets):\n",
        "                if top_k_preds.shape[1] >= 2 and target in top_k_preds[i, :2]:\n",
        "                    self.top2_correct += 1\n",
        "                if top_k_preds.shape[1] >= 3 and target in top_k_preds[i, :3]:\n",
        "                    self.top3_correct += 1\n",
        "\n",
        "    def compute(self):\n",
        "        if self.total_chars == 0:\n",
        "            return {}\n",
        "\n",
        "        return {\n",
        "            'ocr_char_accuracy': self.correct_chars / self.total_chars,\n",
        "            'ocr_top2_accuracy': self.top2_correct / self.total_chars,\n",
        "            'ocr_top3_accuracy': self.top3_correct / self.total_chars,\n",
        "            'ocr_similarity_aware_accuracy': self.similarity_score / self.total_chars,\n",
        "        }\n",
        "\n",
        "print('OCR metrics module loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e25dad-3",
      "metadata": {
        "id": "c0e25dad-3"
      },
      "source": [
        "## Enhanced Trainer with Checkpoint Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e4287274-2",
      "metadata": {
        "id": "e4287274-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6f777a-083b-4252-dc67-188765fed49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined segmentation trainer defined with checkpoint integration\n"
          ]
        }
      ],
      "source": [
        "# Custom Trainer for Refined Training (FIXED)\n",
        "from ultralytics.models.yolo.segment import SegmentationTrainer\n",
        "from ultralytics import YOLO\n",
        "\n",
        "class RefinedSegmentationTrainer(SegmentationTrainer):\n",
        "    \"\"\"\n",
        "    Refined trainer with:\n",
        "    - Progressive layer unfreezing\n",
        "    - Enhanced loss function\n",
        "    - OCR-specific metrics tracking\n",
        "    - Integrated checkpoint management\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg=None, overrides=None, _callbacks=None, checkpoint_manager=None):\n",
        "        # CRITICAL FIX: Add missing config attributes BEFORE calling super().__init__\n",
        "        if overrides is None:\n",
        "            overrides = {}\n",
        "\n",
        "        # Add all missing attributes that Ultralytics might check\n",
        "        overrides.update({\n",
        "            'compile': False,\n",
        "            'freeze': None,\n",
        "            'v5loader': False,\n",
        "            'save_hybrid': False,\n",
        "        })\n",
        "\n",
        "        super().__init__(cfg, overrides, _callbacks)\n",
        "\n",
        "        self.checkpoint_manager = checkpoint_manager\n",
        "\n",
        "        # Get total epochs from config\n",
        "        total_epochs = self.args.epochs if hasattr(self.args, 'epochs') else 40\n",
        "\n",
        "        # Initialize refined loss\n",
        "        self.character_loss_fn = RefinedSimilarityAwareTopKLoss(\n",
        "            num_classes=NUM_CLASSES,\n",
        "            similarity_matrix=similarity_matrix,\n",
        "            k=3,\n",
        "            initial_temperature=0.5,\n",
        "            base_weight=0.5,\n",
        "            topk_weight=0.5,\n",
        "            epochs=total_epochs\n",
        "        ).to(device)\n",
        "\n",
        "        # OCR metrics\n",
        "        self.ocr_metrics = OCRMetrics(similarity_matrix=similarity_matrix)\n",
        "\n",
        "        # Training phase tracking\n",
        "        self.phase = 1\n",
        "        self.freeze_applied = False\n",
        "\n",
        "        # Track best loss for checkpoint saving\n",
        "        self.best_cls_loss = float('inf')\n",
        "\n",
        "        print(f'Trainer initialized with {total_epochs} total epochs')\n",
        "\n",
        "    def _setup_train(self):\n",
        "        \"\"\"Override to apply layer freezing for Phase 1.\"\"\"\n",
        "        super()._setup_train()\n",
        "\n",
        "        if not self.freeze_applied and self.epoch < 12:\n",
        "            print(f'\\nPHASE 1: Classifier Head Fine-Tuning (Epochs 1-12)')\n",
        "            print('Freezing backbone and segmentation layers...')\n",
        "\n",
        "            # Freeze all layers except classification head\n",
        "            for name, param in self.model.named_parameters():\n",
        "                # Keep classification layers trainable\n",
        "                if 'cls' in name.lower() or 'cv3' in name.lower():\n",
        "                    param.requires_grad = True\n",
        "                else:\n",
        "                    param.requires_grad = False\n",
        "\n",
        "            trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "            total = sum(p.numel() for p in self.model.parameters())\n",
        "            print(f'Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)')\n",
        "            self.freeze_applied = True\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        \"\"\"Handle phase transitions and progressive unfreezing.\"\"\"\n",
        "        super().on_train_epoch_start()\n",
        "\n",
        "        # Update temperature in loss\n",
        "        self.character_loss_fn.update_epoch(self.epoch)\n",
        "\n",
        "        # Phase 2: Progressive unfreezing (epochs 12-24)\n",
        "        if self.epoch == 12:\n",
        "            self.phase = 2\n",
        "            print(f'\\nPHASE 2: Progressive Unfreezing (Epochs 13-24)')\n",
        "            print('Unfreezing segmentation head...')\n",
        "\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if 'seg' in name.lower() or 'mask' in name.lower():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "            total = sum(p.numel() for p in self.model.parameters())\n",
        "            print(f'Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)')\n",
        "\n",
        "        # Phase 3: Full fine-tuning (epochs 24+)\n",
        "        elif self.epoch == 24:\n",
        "            self.phase = 3\n",
        "            print(f'\\nPHASE 3: Full Fine-Tuning (Epochs 25-40)')\n",
        "            print('Unfreezing all layers...')\n",
        "\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "            total = sum(p.numel() for p in self.model.parameters())\n",
        "            print(f'Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)')\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        \"\"\"Save checkpoint after each epoch.\"\"\"\n",
        "        super().on_train_epoch_end()\n",
        "\n",
        "        if self.checkpoint_manager:\n",
        "            # Collect metrics\n",
        "            metrics = self._collect_metrics()\n",
        "\n",
        "            # Determine if this is the best model\n",
        "            current_cls_loss = metrics.get('val/cls_loss', float('inf'))\n",
        "            is_best = current_cls_loss < self.best_cls_loss\n",
        "\n",
        "            if is_best:\n",
        "                self.best_cls_loss = current_cls_loss\n",
        "\n",
        "            # Save progress\n",
        "            model_path = Path(self.save_dir) / 'weights' / 'last.pt'\n",
        "            self.checkpoint_manager.save_progress(\n",
        "                epoch=self.epoch,\n",
        "                metrics=metrics,\n",
        "                model_path=str(model_path) if model_path.exists() else None,\n",
        "                is_best=is_best\n",
        "            )\n",
        "\n",
        "    def _collect_metrics(self):\n",
        "        \"\"\"Collect metrics from training.\"\"\"\n",
        "        metrics = {\n",
        "            'phase': self.phase,\n",
        "            'learning_rate': self.optimizer.param_groups[0]['lr'] if hasattr(self, 'optimizer') else 0.0,\n",
        "        }\n",
        "\n",
        "        # Get loss values\n",
        "        if hasattr(self, 'loss_items') and self.loss_items is not None:\n",
        "            if len(self.loss_items) > 0:\n",
        "                metrics['train/cls_loss'] = float(self.loss_items[0])\n",
        "            if len(self.loss_items) > 1:\n",
        "                metrics['train/seg_loss'] = float(self.loss_items[1])\n",
        "            if len(self.loss_items) > 2:\n",
        "                metrics['train/box_loss'] = float(self.loss_items[2])\n",
        "\n",
        "        # Get validation metrics from validator\n",
        "        if hasattr(self, 'validator') and hasattr(self.validator, 'metrics'):\n",
        "            val_metrics = self.validator.metrics\n",
        "            if hasattr(val_metrics, 'results_dict'):\n",
        "                val_dict = val_metrics.results_dict\n",
        "                metrics.update({\n",
        "                    'val/cls_loss': val_dict.get('val/cls_loss', 0.0),\n",
        "                    'val/seg_loss': val_dict.get('val/seg_loss', 0.0),\n",
        "                    'val/box_loss': val_dict.get('val/box_loss', 0.0),\n",
        "                    'metrics/precision(M)': val_dict.get('metrics/precision(M)', 0.0),\n",
        "                    'metrics/recall(M)': val_dict.get('metrics/recall(M)', 0.0),\n",
        "                    'metrics/mAP50(M)': val_dict.get('metrics/mAP50(M)', 0.0),\n",
        "                    'metrics/mAP50-95(M)': val_dict.get('metrics/mAP50-95(M)', 0.0),\n",
        "                })\n",
        "\n",
        "        # Add OCR metrics\n",
        "        ocr_results = self.ocr_metrics.compute()\n",
        "        metrics.update(ocr_results)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def on_val_start(self):\n",
        "        super().on_val_start()\n",
        "        self.ocr_metrics.reset()\n",
        "\n",
        "    def on_val_end(self):\n",
        "        super().on_val_end()\n",
        "\n",
        "        # Log OCR metrics\n",
        "        ocr_results = self.ocr_metrics.compute()\n",
        "        if ocr_results:\n",
        "            print(f'\\n[Epoch {self.epoch}] OCR Metrics:')\n",
        "            for key, value in ocr_results.items():\n",
        "                print(f'  {key}: {value:.4f}')\n",
        "\n",
        "    def compute_loss(self, preds, batch):\n",
        "        \"\"\"Compute loss with refined similarity-aware classification.\"\"\"\n",
        "        # Get base YOLO losses\n",
        "        base_loss = super().compute_loss(preds, batch)\n",
        "\n",
        "        # Add custom similarity-aware character classification loss\n",
        "        if len(preds) > 3:\n",
        "            cls_logits = preds[3]\n",
        "            cls_targets = batch['cls'].long()\n",
        "\n",
        "            if cls_logits is not None and cls_targets is not None:\n",
        "                cls_logits_flat = cls_logits.view(-1, NUM_CLASSES)\n",
        "                cls_targets_flat = cls_targets.view(-1)\n",
        "\n",
        "                valid_mask = cls_targets_flat >= 0\n",
        "                if valid_mask.sum() > 0:\n",
        "                    # Compute refined similarity-aware loss\n",
        "                    char_loss = self.character_loss_fn(\n",
        "                        cls_logits_flat[valid_mask],\n",
        "                        cls_targets_flat[valid_mask]\n",
        "                    )\n",
        "\n",
        "                    # Update OCR metrics\n",
        "                    with torch.no_grad():\n",
        "                        preds_cls = cls_logits_flat[valid_mask].argmax(dim=1)\n",
        "                        top_k_preds = torch.topk(cls_logits_flat[valid_mask], k=3, dim=1)[1]\n",
        "                        self.ocr_metrics.update(\n",
        "                            preds_cls,\n",
        "                            cls_targets_flat[valid_mask],\n",
        "                            top_k_preds\n",
        "                        )\n",
        "\n",
        "                    # Phase-dependent weighting\n",
        "                    if self.phase == 1:\n",
        "                        # Phase 1: Heavy emphasis on classification\n",
        "                        cls_weight = 0.7\n",
        "                    elif self.phase == 2:\n",
        "                        # Phase 2: Balanced\n",
        "                        cls_weight = 0.5\n",
        "                    else:\n",
        "                        # Phase 3: Standard weighting\n",
        "                        cls_weight = 0.3\n",
        "\n",
        "                    total_loss = (1 - cls_weight) * base_loss + cls_weight * char_loss\n",
        "                    return total_loss\n",
        "\n",
        "        return base_loss\n",
        "\n",
        "print('Refined segmentation trainer defined with checkpoint integration')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b00e62a",
      "metadata": {
        "id": "0b00e62a"
      },
      "source": [
        "## Load Pretrained Model and Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "b4b8d469",
      "metadata": {
        "id": "b4b8d469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821ac650-ce7a-486a-d1bc-19639ce0e6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found. Starting fresh training from: /content/ocr_project/models/custom_ocr_last.pt\n",
            "Model loaded successfully\n",
            "\n",
            "Model ready for training\n"
          ]
        }
      ],
      "source": [
        "# Load model with resume capability\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Check if we should resume from checkpoint\n",
        "checkpoint_info = checkpoint_manager.get_last_checkpoint()\n",
        "\n",
        "if checkpoint_info['exists'] and checkpoint_info['last_model_path']:\n",
        "    print(f'Found previous checkpoint at epoch {checkpoint_info[\"last_epoch\"]}')\n",
        "    print(f'Last model: {checkpoint_info[\"last_model_path\"]}')\n",
        "\n",
        "    # Ask user if they want to resume\n",
        "    resume_choice = input('Do you want to resume training from checkpoint? (y/n): ').lower().strip()\n",
        "\n",
        "    if resume_choice == 'y':\n",
        "        model_path = checkpoint_info['last_model_path']\n",
        "        print(f'Resuming from checkpoint: {model_path}')\n",
        "        RESUME_TRAINING = True\n",
        "    else:\n",
        "        model_path = PRETRAINED_MODEL_PATH\n",
        "        print(f'Starting fresh training from: {model_path}')\n",
        "        RESUME_TRAINING = False\n",
        "else:\n",
        "    model_path = PRETRAINED_MODEL_PATH\n",
        "    RESUME_TRAINING = False\n",
        "    print(f'No checkpoint found. Starting fresh training from: {model_path}')\n",
        "\n",
        "# Load the model\n",
        "if model_path and os.path.exists(model_path):\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        print(f'Model loaded successfully')\n",
        "    except Exception as e:\n",
        "        print(f'ERROR loading model {model_path}: {e}')\n",
        "        print('Loading default YOLO model...')\n",
        "        model = YOLO('yolo11n-seg.pt')\n",
        "else:\n",
        "    print(f'Model path not found: {model_path}')\n",
        "    print('Loading default YOLO model...')\n",
        "    model = YOLO('yolo11n-seg.pt')\n",
        "\n",
        "# Set custom trainer\n",
        "model.trainer = RefinedSegmentationTrainer\n",
        "\n",
        "print('\\nModel ready for training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77ae0242",
      "metadata": {
        "id": "77ae0242"
      },
      "source": [
        "## Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "bada4767",
      "metadata": {
        "id": "bada4767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea08d52-a082-4c2e-bf08-e04ece1a98a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Training Configuration:\n",
            "  Epochs: 40\n",
            "  Batch size: 16\n",
            "  Learning rate: 0.005 -> 0.0001\n",
            "  Augmentations: Enhanced HSV + Erasing + Geometric\n",
            "\n",
            "Training Strategy:\n",
            "  Phase 1 (1-12): Classifier head only\n",
            "  Phase 2 (13-24): + Segmentation head\n",
            "  Phase 3 (25-40): All layers\n"
          ]
        }
      ],
      "source": [
        "# Refined training hyperparameters\n",
        "REFINE_EPOCHS = 40\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Learning rate schedule\n",
        "LR0 = 0.005\n",
        "LRF = 0.0001\n",
        "\n",
        "# Optimizer settings\n",
        "MOMENTUM = 0.937\n",
        "WEIGHT_DECAY = 5e-4\n",
        "WARMUP_EPOCHS = 3.0\n",
        "\n",
        "# Augmentations\n",
        "AUG_HSV_H = 0.02\n",
        "AUG_HSV_S = 0.8\n",
        "AUG_HSV_V = 0.5\n",
        "AUG_ERASING = 0.5\n",
        "AUG_DEGREES = 5.0\n",
        "AUG_SHEAR = 2.0\n",
        "\n",
        "# Disabled augmentations (not useful for OCR)\n",
        "AUG_FLIPLR = 0.0\n",
        "AUG_MOSAIC = 0.0\n",
        "AUG_MIXUP = 0.0\n",
        "\n",
        "print('Refined Training Configuration:')\n",
        "print(f'  Epochs: {REFINE_EPOCHS}')\n",
        "print(f'  Batch size: {BATCH_SIZE}')\n",
        "print(f'  Learning rate: {LR0} -> {LRF}')\n",
        "print(f'  Augmentations: Enhanced HSV + Erasing + Geometric')\n",
        "print(f'\\nTraining Strategy:')\n",
        "print(f'  Phase 1 (1-12): Classifier head only')\n",
        "print(f'  Phase 2 (13-24): + Segmentation head')\n",
        "print(f'  Phase 3 (25-40): All layers')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eeb804e",
      "metadata": {
        "id": "7eeb804e"
      },
      "source": [
        "## Execute Refined Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "8cc4bac1",
      "metadata": {
        "id": "8cc4bac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b67648d-b98b-4405-8fc1-d71a45cce564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ 'save_hybrid' is deprecated and will be removed in the future.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'\u001b[31m\u001b[1mfreeze\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mv5loader\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-ba964244-ab08-4d60-b09b-02a2b06d21b7.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ['detect', 'obb', 'pose', 'segment', 'classify']\n                MODE (required) is one of ['export', 'val', 'benchmark', 'predict', 'track', 'train']\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Validate a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or any of ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"/tmp/ipython-input-2900728501.py\"\u001b[0m, line \u001b[1;32m64\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    trainer = RefinedSegmentationTrainer(\n",
            "  File \u001b[1;32m\"/tmp/ipython-input-2422048064.py\"\u001b[0m, line \u001b[1;32m27\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/segment/train.py\"\u001b[0m, line \u001b[1;32m40\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\"\u001b[0m, line \u001b[1;32m63\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\"\u001b[0m, line \u001b[1;32m124\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0m, line \u001b[1;32m310\u001b[0m, in \u001b[1;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.12/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0;36m, line \u001b[0;32m505\u001b[0;36m, in \u001b[0;35mcheck_dict_alignment\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mfreeze\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mv5loader\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-ba964244-ab08-4d60-b09b-02a2b06d21b7.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of ['detect', 'obb', 'pose', 'segment', 'classify']\n                MODE (required) is one of ['export', 'val', 'benchmark', 'predict', 'track', 'train']\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Validate a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or any of ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import ultralytics\n",
        "from ultralytics.cfg import get_cfg\n",
        "\n",
        "# Training parameters\n",
        "train_params = dict(\n",
        "    data=DATA_YAML_PATH,\n",
        "    epochs=REFINE_EPOCHS,\n",
        "    batch=BATCH_SIZE,\n",
        "    imgsz=IMG_SIZE,\n",
        "    compile=False,\n",
        "\n",
        "    # Specify the model path for the trainer\n",
        "    model=model_path,\n",
        "\n",
        "    # Explicitly define the task for Ultralytics\n",
        "    task='segment',\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer='SGD',\n",
        "    lr0=LR0,\n",
        "    lrf=LRF,\n",
        "    momentum=MOMENTUM,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "\n",
        "    # Warmup\n",
        "    warmup_epochs=WARMUP_EPOCHS,\n",
        "    warmup_momentum=0.8,\n",
        "    warmup_bias_lr=0.1,\n",
        "\n",
        "    # Augmentations\n",
        "    hsv_h=AUG_HSV_H,\n",
        "    hsv_s=AUG_HSV_S,\n",
        "    hsv_v=AUG_HSV_V,\n",
        "    erasing=AUG_ERASING,\n",
        "    degrees=AUG_DEGREES,\n",
        "    shear=AUG_SHEAR,\n",
        "    fliplr=AUG_FLIPLR,\n",
        "    mosaic=AUG_MOSAIC,\n",
        "    mixup=AUG_MIXUP,\n",
        "\n",
        "    # Output settings\n",
        "    project='refined_training',\n",
        "    name=experiment_name,\n",
        "    exist_ok=True,\n",
        "\n",
        "    # Validation and saving\n",
        "    val=True,\n",
        "    save=True,\n",
        "    save_period=5,  # Save local copy every 5 epochs\n",
        "\n",
        "    # System\n",
        "    device=device,\n",
        "    amp=True,\n",
        "    seed=42,\n",
        "    deterministic=True,\n",
        "    single_cls=False,\n",
        "\n",
        "    # Resume handling\n",
        "    resume=RESUME_TRAINING,\n",
        ")\n",
        "\n",
        "# Create a custom trainer instance with checkpoint manager\n",
        "trainer = RefinedSegmentationTrainer(\n",
        "    cfg=train_params,\n",
        "    checkpoint_manager=checkpoint_manager\n",
        ")\n",
        "\n",
        "print(f'\\n{'='*80}')\n",
        "if RESUME_TRAINING:\n",
        "    print(f'RESUMING TRAINING FROM CHECKPOINT')\n",
        "else:\n",
        "    print(f'STARTING FRESH TRAINING')\n",
        "print(f'{'='*80}\\n')\n",
        "print(f'Start time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}')\n",
        "print(f'Device: {device}')\n",
        "print(f'Experiment: {experiment_name}')\n",
        "print(f'Checkpoint CSV: {checkpoint_manager.csv_path}')\n",
        "if checkpoint_manager.drive_dir:\n",
        "    print(f'Drive backup: {checkpoint_manager.drive_dir}')\n",
        "print()\n",
        "\n",
        "# Execute training\n",
        "try:\n",
        "    results = trainer.train() # Removed 'model' argument\n",
        "\n",
        "    print(f'\\n{'='*80}')\n",
        "    print(f'TRAINING COMPLETED SUCCESSFULLY')\n",
        "    print(f'{'='*80}\\n')\n",
        "    print(f'End time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}')\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(f'\\nTraining interrupted by user')\n",
        "    print(f'Progress saved to: {checkpoint_manager.csv_path}')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'\\nTraining failed with error: {e}')\n",
        "    print(f'Progress saved to: {checkpoint_manager.csv_path}')\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9dbebfb",
      "metadata": {
        "id": "b9dbebfb"
      },
      "source": [
        "## Save Final Models and Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507bd7ec",
      "metadata": {
        "id": "507bd7ec"
      },
      "outputs": [],
      "source": [
        "# Final export of models\n",
        "print('\\n=== FINAL MODEL EXPORT ===')\n",
        "\n",
        "# Get paths from trainer\n",
        "if 'trainer' in locals() and hasattr(trainer, 'save_dir'):\n",
        "    results_dir = trainer.save_dir\n",
        "\n",
        "    # Find best and last models\n",
        "    best_model_local = Path(results_dir) / 'weights' / 'best.pt'\n",
        "    last_model_local = Path(results_dir) / 'weights' / 'last.pt'\n",
        "\n",
        "    # Check if models exist\n",
        "    models_found = []\n",
        "\n",
        "    if best_model_local.exists():\n",
        "        models_found.append(('best', best_model_local))\n",
        "\n",
        "    if last_model_local.exists():\n",
        "        models_found.append(('last', last_model_local))\n",
        "\n",
        "    # Also check checkpoint manager\n",
        "    if checkpoint_manager.best_model_local.exists():\n",
        "        models_found.append(('checkpoint_best', checkpoint_manager.best_model_local))\n",
        "\n",
        "    if checkpoint_manager.last_model_local.exists():\n",
        "        models_found.append(('checkpoint_last', checkpoint_manager.last_model_local))\n",
        "\n",
        "    # Copy models to final export directory\n",
        "    export_dir = Path(LOCAL_ROOT) / 'final_models' / experiment_name\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for model_name, model_path in models_found:\n",
        "        export_path = export_dir / f'{model_name}.pt'\n",
        "        shutil.copy2(model_path, export_path)\n",
        "        print(f'Exported {model_name} model to: {export_path}')\n",
        "\n",
        "        # Also copy to Drive if available\n",
        "        if checkpoint_manager.drive_dir:\n",
        "            drive_export_path = checkpoint_manager.drive_dir / 'final_models' / f'{model_name}.pt'\n",
        "            drive_export_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(model_path, drive_export_path)\n",
        "            print(f'  Backup to Drive: {drive_export_path}')\n",
        "\n",
        "    # Export results CSV\n",
        "    results_csv = Path(results_dir) / 'results.csv'\n",
        "    if results_csv.exists():\n",
        "        export_csv = export_dir / 'training_results.csv'\n",
        "        shutil.copy2(results_csv, export_csv)\n",
        "        print(f'\\nExported results CSV to: {export_csv}')\n",
        "\n",
        "    # Also export our checkpoint CSV\n",
        "    if checkpoint_manager.csv_path.exists():\n",
        "        checkpoint_csv = export_dir / 'checkpoint_progress.csv'\n",
        "        shutil.copy2(checkpoint_manager.csv_path, checkpoint_csv)\n",
        "        print(f'Exported checkpoint CSV to: {checkpoint_csv}')\n",
        "\n",
        "    print(f'\\nAll models and results exported to: {export_dir}')\n",
        "\n",
        "else:\n",
        "    print('Trainer not found. Using checkpoint manager models.')\n",
        "\n",
        "    # Export from checkpoint manager\n",
        "    export_dir = Path(LOCAL_ROOT) / 'final_models' / experiment_name\n",
        "    export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if checkpoint_manager.best_model_local.exists():\n",
        "        export_path = export_dir / 'best_model.pt'\n",
        "        shutil.copy2(checkpoint_manager.best_model_local, export_path)\n",
        "        print(f'Exported best model to: {export_path}')\n",
        "\n",
        "    if checkpoint_manager.last_model_local.exists():\n",
        "        export_path = export_dir / 'last_model.pt'\n",
        "        shutil.copy2(checkpoint_manager.last_model_local, export_path)\n",
        "        print(f'Exported last model to: {export_path}')\n",
        "\n",
        "    if checkpoint_manager.csv_path.exists():\n",
        "        export_csv = export_dir / 'training_progress.csv'\n",
        "        shutil.copy2(checkpoint_manager.csv_path, export_csv)\n",
        "        print(f'\\nExported progress CSV to: {export_csv}')\n",
        "\n",
        "print('\\n=== EXPORT COMPLETE ===')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ebcce99",
      "metadata": {
        "id": "6ebcce99"
      },
      "source": [
        "## Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "208e10e5",
      "metadata": {
        "id": "208e10e5"
      },
      "outputs": [],
      "source": [
        "# Load and analyze training progress\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load progress from checkpoint manager\n",
        "progress_df = checkpoint_manager.load_progress()\n",
        "\n",
        "if not progress_df.empty:\n",
        "    print('\\n=== TRAINING PERFORMANCE ANALYSIS ===')\n",
        "    print(f'Total epochs completed: {len(progress_df)}')\n",
        "\n",
        "    # Get final metrics\n",
        "    final_row = progress_df.iloc[-1]\n",
        "\n",
        "    print('\\nFinal Epoch Metrics:')\n",
        "    print('-' * 80)\n",
        "\n",
        "    # Classification metrics\n",
        "    if 'val/cls_loss' in progress_df.columns:\n",
        "        final_cls_loss = final_row['val/cls_loss']\n",
        "        best_cls_loss = progress_df['val/cls_loss'].min()\n",
        "        best_cls_epoch = progress_df['val/cls_loss'].idxmin() + 1\n",
        "\n",
        "        print(f'Classification Loss:')\n",
        "        print(f'  Final: {final_cls_loss:.4f}')\n",
        "        print(f'  Best:  {best_cls_loss:.4f} (epoch {best_cls_epoch})')\n",
        "\n",
        "    # OCR metrics\n",
        "    if 'ocr_char_accuracy' in progress_df.columns:\n",
        "        final_ocr_acc = final_row['ocr_char_accuracy']\n",
        "        best_ocr_acc = progress_df['ocr_char_accuracy'].max()\n",
        "        best_ocr_epoch = progress_df['ocr_char_accuracy'].idxmax() + 1\n",
        "\n",
        "        print(f'\\nOCR Character Accuracy:')\n",
        "        print(f'  Final: {final_ocr_acc:.4f} ({final_ocr_acc*100:.1f}%)')\n",
        "        print(f'  Best:  {best_ocr_acc:.4f} ({best_ocr_acc*100:.1f}%) (epoch {best_ocr_epoch})')\n",
        "\n",
        "    # Segmentation metrics\n",
        "    if 'metrics/mAP50-95(M)' in progress_df.columns:\n",
        "        final_map = final_row['metrics/mAP50-95(M)']\n",
        "        best_map = progress_df['metrics/mAP50-95(M)'].max()\n",
        "        best_map_epoch = progress_df['metrics/mAP50-95(M)'].idxmax() + 1\n",
        "\n",
        "        print(f'\\nSegmentation mAP@50-95:')\n",
        "        print(f'  Final: {final_map:.4f}')\n",
        "        print(f'  Best:  {best_map:.4f} (epoch {best_map_epoch})')\n",
        "\n",
        "    # Plot training curves\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'Training Performance - {experiment_name}', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Plot 1: Classification Loss\n",
        "    if 'val/cls_loss' in progress_df.columns:\n",
        "        ax = axes[0, 0]\n",
        "        epochs = progress_df['epoch']\n",
        "\n",
        "        if 'train/cls_loss' in progress_df.columns:\n",
        "            ax.plot(epochs, progress_df['train/cls_loss'], label='Train', linewidth=2, alpha=0.7)\n",
        "\n",
        "        ax.plot(epochs, progress_df['val/cls_loss'], label='Validation', linewidth=2)\n",
        "\n",
        "        # Mark phase transitions\n",
        "        ax.axvline(x=12, color='gray', linestyle=':', alpha=0.5, label='Phase 1→2')\n",
        "        ax.axvline(x=24, color='gray', linestyle=':', alpha=0.5, label='Phase 2→3')\n",
        "\n",
        "        ax.set_xlabel('Epoch', fontweight='bold')\n",
        "        ax.set_ylabel('Loss', fontweight='bold')\n",
        "        ax.set_title('Classification Loss', fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "\n",
        "    # Plot 2: OCR Accuracy\n",
        "    if 'ocr_char_accuracy' in progress_df.columns:\n",
        "        ax = axes[0, 1]\n",
        "        ax.plot(epochs, progress_df['ocr_char_accuracy'] * 100, label='Char Accuracy', linewidth=2)\n",
        "\n",
        "        if 'ocr_top2_accuracy' in progress_df.columns:\n",
        "            ax.plot(epochs, progress_df['ocr_top2_accuracy'] * 100, label='Top-2 Accuracy', linewidth=2, alpha=0.7)\n",
        "\n",
        "        if 'ocr_top3_accuracy' in progress_df.columns:\n",
        "            ax.plot(epochs, progress_df['ocr_top3_accuracy'] * 100, label='Top-3 Accuracy', linewidth=2, alpha=0.5)\n",
        "\n",
        "        ax.axvline(x=12, color='gray', linestyle=':', alpha=0.5)\n",
        "        ax.axvline(x=24, color='gray', linestyle=':', alpha=0.5)\n",
        "\n",
        "        ax.set_xlabel('Epoch', fontweight='bold')\n",
        "        ax.set_ylabel('Accuracy (%)', fontweight='bold')\n",
        "        ax.set_title('OCR Performance', fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "        ax.set_ylim([0, 105])\n",
        "\n",
        "    # Plot 3: Segmentation mAP\n",
        "    if 'metrics/mAP50-95(M)' in progress_df.columns:\n",
        "        ax = axes[1, 0]\n",
        "        ax.plot(epochs, progress_df['metrics/mAP50-95(M)'], linewidth=2, color='green')\n",
        "\n",
        "        ax.axvline(x=12, color='gray', linestyle=':', alpha=0.5)\n",
        "        ax.axvline(x=24, color='gray', linestyle=':', alpha=0.5)\n",
        "\n",
        "        ax.set_xlabel('Epoch', fontweight='bold')\n",
        "        ax.set_ylabel('mAP@50-95', fontweight='bold')\n",
        "        ax.set_title('Segmentation Quality', fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_ylim([0, 1])\n",
        "\n",
        "    # Plot 4: Learning Rate\n",
        "    if 'learning_rate' in progress_df.columns:\n",
        "        ax = axes[1, 1]\n",
        "        ax.plot(epochs, progress_df['learning_rate'], linewidth=2, color='purple')\n",
        "\n",
        "        ax.axvline(x=12, color='gray', linestyle=':', alpha=0.5)\n",
        "        ax.axvline(x=24, color='gray', linestyle=':', alpha=0.5)\n",
        "\n",
        "        ax.set_xlabel('Epoch', fontweight='bold')\n",
        "        ax.set_ylabel('Learning Rate', fontweight='bold')\n",
        "        ax.set_title('Learning Rate Schedule', fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_yscale('log')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot\n",
        "    plot_path = export_dir / 'training_analysis.png'\n",
        "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "    print(f'\\nTraining analysis plot saved to: {plot_path}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print('No training progress data found.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "### Key Improvements:\n",
        "\n",
        "1. **Reproducibility**:\n",
        "   - Dataset downloaded from public Google Drive folder\n",
        "   - No hardcoded paths - works from any account\n",
        "   - Automatic dataset verification and fixing\n",
        "   \n",
        "2. **Robust Checkpoint System**:\n",
        "   - CSV saved EVERY epoch (no exceptions)\n",
        "   - Models saved to Google Drive every epoch (if mounted)\n",
        "   - Automatic resume capability\n",
        "   - Threaded async saves to prevent training slowdown\n",
        "   \n",
        "3. **Clean Output**:\n",
        "   - Clear, professional logging\n",
        "   \n",
        "4. **Sanity Checks**:\n",
        "   - Dataset structure verification\n",
        "   - File existence checks\n",
        "   - Model loading error handling\n",
        "   - Automatic path fixing in data.yaml"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}