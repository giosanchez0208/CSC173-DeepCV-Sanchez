{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f6d1e2",
   "metadata": {},
   "source": [
    "# Philippine License Plate Character Instance Segmentation with Similarity-Aware Loss\n",
    "\n",
    "Single-stage training: YOLO11-seg with polygon masks and character labels, using a custom similarity-aware loss function to handle visually confusable characters (O/0, I/1/L, etc.) in CCTV surveillance footage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79720b9a",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "This notebook is optimized for Google Colab with a T4 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U ultralytics --quiet\n",
    "\n",
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be0f6b",
   "metadata": {},
   "source": [
    "## 1. Paths and Configuration Variables\n",
    "\n",
    "Set these to the actual dataset and output locations before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f34f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML_PATH = '/content/philippine_lp_chars.yaml'\n",
    "RUN_PROJECT = 'philippine_lp_ocr'\n",
    "RUN_NAME = 'seg_with_similarity_loss'\n",
    "EXPORT_DIR = '/content/exports'\n",
    "\n",
    "!mkdir -p \"$EXPORT_DIR\"\n",
    "print('DATA_YAML_PATH:', DATA_YAML_PATH)\n",
    "print('EXPORT_DIR:', EXPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891aee20",
   "metadata": {},
   "source": [
    "## 2. Imports\n",
    "\n",
    "Core dependencies for segmentation training, custom loss, and optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.segment import SegmentationTrainer\n",
    "from ultralytics.nn.tasks import SegmentationModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144851a",
   "metadata": {},
   "source": [
    "## 3. Character Set and Similarity Matrix\n",
    "\n",
    "Define the 36-class character set (A–Z, 0–9) and visual-similarity relationships based on glyph shapes. Characters in the same group (e.g., O, 0, Q) are visually similar and should receive reduced penalties when confused during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = [chr(i) for i in range(65, 91)] + [str(i) for i in range(10)]\n",
    "NUM_CLASSES = len(CHARS)\n",
    "CHAR_TO_IDX = {c: i for i, c in enumerate(CHARS)}\n",
    "IDX_TO_CHAR = {i: c for i, c in enumerate(CHARS)}\n",
    "\n",
    "print('Number of classes:', NUM_CLASSES)\n",
    "print('Characters:', CHARS)\n",
    "\n",
    "SIMILAR_GROUPS = [\n",
    "    ['O', '0', 'Q'],\n",
    "    ['I', '1', 'L'],\n",
    "    ['S', '5'],\n",
    "    ['Z', '2'],\n",
    "    ['B', '8'],\n",
    "    ['D', '0'],\n",
    "    ['G', 'C'],\n",
    "    ['U', 'V'],\n",
    "    ['P', 'R'],\n",
    "]\n",
    "\n",
    "def create_similarity_matrix(num_classes=NUM_CLASSES, groups=SIMILAR_GROUPS, base_sim=0.6):\n",
    "    S = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    for group in groups:\n",
    "        idxs = [CHAR_TO_IDX[c] for c in group if c in CHAR_TO_IDX]\n",
    "        for i in idxs:\n",
    "            for j in idxs:\n",
    "                if i != j:\n",
    "                    S[i, j] = base_sim\n",
    "    return torch.tensor(S, dtype=torch.float32)\n",
    "\n",
    "similarity_matrix = create_similarity_matrix()\n",
    "print('Similarity matrix shape:', similarity_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bc7a1",
   "metadata": {},
   "source": [
    "### 3.1. Dynamic Similarity Matrix Updates\n",
    "\n",
    "**Logic:** The similarity matrix is initialized with hand-crafted visual similarities, but real-world confusion patterns may differ. By tracking which characters the model actually confuses during validation, we can dynamically update the similarity matrix to better reflect learned confusion patterns. This creates an adaptive training process where the loss function becomes more intelligent over time, focusing on the model's actual weak points rather than theoretical similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicSimilarityMatrix:\n",
    "    \"\"\"Tracks confusion during validation and updates similarity matrix dynamically.\"\"\"\n",
    "    def __init__(self, num_classes=NUM_CLASSES, initial_matrix=None, learning_rate=0.1):\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "        self.similarity_matrix = initial_matrix.cpu().numpy() if initial_matrix is not None else create_similarity_matrix().numpy()\n",
    "        \n",
    "    def update_confusion(self, predictions, targets):\n",
    "        \"\"\"Accumulate confusion from a batch of predictions.\"\"\"\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            if 0 <= target < self.num_classes and 0 <= pred < self.num_classes:\n",
    "                self.confusion_matrix[target, pred] += 1\n",
    "    \n",
    "    def compute_similarity_from_confusion(self):\n",
    "        \"\"\"Convert confusion matrix to similarity scores.\"\"\"\n",
    "        # Normalize each row by the number of times that class appeared\n",
    "        row_sums = self.confusion_matrix.sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "        normalized_confusion = self.confusion_matrix / row_sums\n",
    "        \n",
    "        # High confusion rate = high similarity\n",
    "        # Clip to [0, 1] and exclude diagonal (self-similarity stays 1.0)\n",
    "        similarity_from_confusion = normalized_confusion.copy()\n",
    "        np.fill_diagonal(similarity_from_confusion, 1.0)\n",
    "        \n",
    "        return similarity_from_confusion\n",
    "    \n",
    "    def update_similarity_matrix(self):\n",
    "        \"\"\"Update similarity matrix using exponential moving average of confusion patterns.\"\"\"\n",
    "        new_similarity = self.compute_similarity_from_confusion()\n",
    "        \n",
    "        # Exponential moving average: S_new = (1-lr) * S_old + lr * S_from_confusion\n",
    "        self.similarity_matrix = (1 - self.learning_rate) * self.similarity_matrix + \\\n",
    "                                  self.learning_rate * new_similarity\n",
    "        \n",
    "        # Reset confusion matrix for next validation period\n",
    "        self.confusion_matrix.fill(0)\n",
    "        \n",
    "        return torch.tensor(self.similarity_matrix, dtype=torch.float32)\n",
    "    \n",
    "    def get_similarity_matrix(self):\n",
    "        return torch.tensor(self.similarity_matrix, dtype=torch.float32)\n",
    "\n",
    "# Initialize dynamic similarity matrix manager\n",
    "dynamic_sim_matrix = DynamicSimilarityMatrix(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    initial_matrix=similarity_matrix,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "print('Dynamic similarity matrix manager initialized.')\n",
    "print('Will update every validation epoch based on actual confusion patterns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d38971",
   "metadata": {},
   "source": [
    "## 4. Custom Similarity-Aware Loss Function\n",
    "\n",
    "Similarity-aware top-k loss directly rewards the model when visually similar characters appear in the top-2 predictions. If the model is uncertain between O and 0, having both in the top-2 with high confidence is acceptable and should be penalized less than confidently predicting X when the answer is O. This matches the requirement of considering \"top-K outputs (e.g., top-2) rather than only the single best prediction.\" [https://openaccess.thecvf.com/content_cvpr_2016/papers/Lapin_Loss_Functions_for_CVPR_2016_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2016/papers/Lapin_Loss_Functions_for_CVPR_2016_paper.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityAwareTopKLoss(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, similarity_matrix=None,\n",
    "                 k=2, temperature=1.0, base_weight=0.7, topk_weight=0.3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "        self.base_weight = base_weight\n",
    "        self.topk_weight = topk_weight\n",
    "        if similarity_matrix is not None:\n",
    "            self.register_buffer('similarity_matrix', similarity_matrix)\n",
    "        else:\n",
    "            self.register_buffer('similarity_matrix', create_similarity_matrix())\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        B = logits.size(0)\n",
    "        device = logits.device\n",
    "\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        probs = F.softmax(logits / self.temperature, dim=1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, self.k, dim=1)\n",
    "\n",
    "        sim_loss = torch.zeros(B, device=device)\n",
    "        for i in range(B):\n",
    "            t = targets[i].item()\n",
    "            sims = self.similarity_matrix[t][topk_indices[i]]\n",
    "            penalties = 1.0 - sims\n",
    "            weighted_penalties = topk_probs[i] * penalties\n",
    "            sim_loss[i] = weighted_penalties.sum()\n",
    "\n",
    "        total = self.base_weight * ce_loss + self.topk_weight * sim_loss\n",
    "        return total.mean()\n",
    "\n",
    "print('Similarity-aware loss defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0ae7a",
   "metadata": {},
   "source": [
    "### 4.1. Loss Function Refinements: Temperature Annealing & Adaptive Weighting\n",
    "\n",
    "**Logic:** Temperature scheduling helps the model transition from exploration to exploitation. Early in training (high temperature), the model explores various character hypotheses with softer penalties. As training progresses (lower temperature), the model commits to more confident predictions. This is crucial for OCR where early confusion helps learn feature relationships, but later training needs sharp decisions.\n",
    "\n",
    "Adaptive weighting based on prediction confidence dynamically balances between base cross-entropy and similarity-aware loss. When the model is uncertain (low confidence), we rely more on similarity-aware loss to guide learning with soft constraints. When confident, we trust the model's strong predictions and rely more on standard cross-entropy. This creates a self-regulating loss that adapts to the model's learning stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ad13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedSimilarityAwareTopKLoss(nn.Module):\n",
    "    \"\"\"Enhanced loss with temperature annealing and confidence-based adaptive weighting.\"\"\"\n",
    "    def __init__(self, num_classes=NUM_CLASSES, similarity_matrix=None,\n",
    "                 k=2, initial_temperature=1.0, base_weight=0.7, topk_weight=0.3,\n",
    "                 epochs=300):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.k = k\n",
    "        self.initial_temperature = initial_temperature\n",
    "        self.base_weight = base_weight\n",
    "        self.topk_weight = topk_weight\n",
    "        self.epochs = epochs\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        if similarity_matrix is not None:\n",
    "            self.register_buffer('similarity_matrix', similarity_matrix)\n",
    "        else:\n",
    "            self.register_buffer('similarity_matrix', create_similarity_matrix())\n",
    "\n",
    "    def update_epoch(self, epoch):\n",
    "        \"\"\"Update current epoch for temperature annealing.\"\"\"\n",
    "        self.current_epoch = epoch\n",
    "    \n",
    "    def get_temperature(self):\n",
    "        \"\"\"Anneal temperature from initial_temperature to 0.5 over training.\"\"\"\n",
    "        progress = self.current_epoch / max(self.epochs, 1)\n",
    "        return max(0.5, self.initial_temperature - progress * 0.8)\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        B = logits.size(0)\n",
    "        device = logits.device\n",
    "        \n",
    "        # Get current temperature for this epoch\n",
    "        temperature = self.get_temperature()\n",
    "        \n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        probs = F.softmax(logits / temperature, dim=1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, self.k, dim=1)\n",
    "        \n",
    "        # Compute similarity-aware loss\n",
    "        sim_loss = torch.zeros(B, device=device)\n",
    "        max_confidences = []\n",
    "        \n",
    "        for i in range(B):\n",
    "            t = targets[i].item()\n",
    "            sims = self.similarity_matrix[t][topk_indices[i]]\n",
    "            penalties = 1.0 - sims\n",
    "            weighted_penalties = topk_probs[i] * penalties\n",
    "            sim_loss[i] = weighted_penalties.sum()\n",
    "            max_confidences.append(topk_probs[i].max().item())\n",
    "        \n",
    "        # Adaptive weighting based on confidence\n",
    "        # Low confidence: rely more on similarity-aware loss (exploratory)\n",
    "        # High confidence: rely more on standard CE loss (exploitation)\n",
    "        confidence = torch.tensor(max_confidences, device=device)\n",
    "        adaptive_base_weight = self.base_weight * confidence + self.topk_weight * (1 - confidence)\n",
    "        adaptive_topk_weight = self.topk_weight * confidence + self.base_weight * (1 - confidence)\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = adaptive_base_weight + adaptive_topk_weight\n",
    "        adaptive_base_weight = adaptive_base_weight / total_weight\n",
    "        adaptive_topk_weight = adaptive_topk_weight / total_weight\n",
    "        \n",
    "        total = adaptive_base_weight * ce_loss + adaptive_topk_weight * sim_loss\n",
    "        return total.mean()\n",
    "\n",
    "print('Improved similarity-aware loss with temperature annealing and adaptive weighting defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79036a",
   "metadata": {},
   "source": [
    "## 5. Sanity Check for Custom Loss\n",
    "\n",
    "Verify that confusing similar characters (O vs 0) incurs lower penalty than confusing very different characters (O vs X).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SimilarityAwareTopKLoss(num_classes=NUM_CLASSES, similarity_matrix=similarity_matrix, k=2).to(device)\n",
    "\n",
    "logits_similar = torch.zeros(1, NUM_CLASSES, device=device)\n",
    "logits_similar[0, CHAR_TO_IDX['0']] = 5.0\n",
    "target_O = torch.tensor([CHAR_TO_IDX['O']], device=device)\n",
    "loss_similar = loss_fn(logits_similar, target_O)\n",
    "\n",
    "logits_diff = torch.zeros(1, NUM_CLASSES, device=device)\n",
    "logits_diff[0, CHAR_TO_IDX['X']] = 5.0\n",
    "loss_diff = loss_fn(logits_diff, target_O)\n",
    "\n",
    "print(f'Loss (O vs 0): {loss_similar.item():.4f}')\n",
    "print(f'Loss (O vs X): {loss_diff.item():.4f}')\n",
    "assert loss_similar < loss_diff, 'Expected O/0 confusion < O/X confusion'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06f195",
   "metadata": {},
   "source": [
    "## 6. Custom Segmentation Trainer with Similarity-Aware Character Loss\n",
    "\n",
    "Override YOLO's segmentation trainer to inject the similarity-aware loss into the character classification head. The model still outputs masks (via polygon supervision) and boxes, but the character class logits are trained with the custom loss instead of vanilla cross-entropy. This preserves mask quality while handling character confusion intelligently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc75c8f",
   "metadata": {},
   "source": [
    "### 6.1. OCR-Specific Validation Metrics\n",
    "\n",
    "**Logic:** Standard classification metrics (accuracy, precision, recall) don't capture OCR-specific challenges. Character Error Rate (CER) measures individual character mistakes, while Word Error Rate (WER) captures full plate correctness—critical for real applications where partial plate reads are often useless. Top-2/3 accuracy shows if the correct character is among top predictions, indicating \"close but not quite\" scenarios. Similarity-aware accuracy gives partial credit for confusing similar characters (O vs 0), providing a more nuanced view of model performance that aligns with the similarity-aware loss. These metrics together give a complete picture of OCR quality beyond simple accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0534032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRMetrics:\n",
    "    \"\"\"Compute OCR-specific validation metrics.\"\"\"\n",
    "    def __init__(self, similarity_matrix=None):\n",
    "        self.similarity_matrix = similarity_matrix if similarity_matrix is not None else create_similarity_matrix()\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all accumulated metrics.\"\"\"\n",
    "        self.total_chars = 0\n",
    "        self.correct_chars = 0\n",
    "        self.total_plates = 0\n",
    "        self.correct_plates = 0\n",
    "        self.top2_correct = 0\n",
    "        self.top3_correct = 0\n",
    "        self.similarity_score = 0.0\n",
    "    \n",
    "    def update(self, predictions, targets, top_k_preds=None):\n",
    "        \"\"\"\n",
    "        Update metrics with a batch of predictions.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Tensor of predicted class indices [B]\n",
    "            targets: Tensor of ground truth class indices [B]\n",
    "            top_k_preds: Optional tensor of top-k predictions [B, k] for top-k accuracy\n",
    "        \"\"\"\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        targets = targets.cpu().numpy()\n",
    "        \n",
    "        # Character-level metrics\n",
    "        self.total_chars += len(targets)\n",
    "        self.correct_chars += (predictions == targets).sum()\n",
    "        \n",
    "        # Similarity-aware accuracy (partial credit for similar chars)\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            if 0 <= target < len(self.similarity_matrix) and 0 <= pred < len(self.similarity_matrix):\n",
    "                sim = self.similarity_matrix[target][pred].item()\n",
    "                self.similarity_score += sim\n",
    "        \n",
    "        # Top-k accuracy\n",
    "        if top_k_preds is not None:\n",
    "            top_k_preds = top_k_preds.cpu().numpy()\n",
    "            for i, target in enumerate(targets):\n",
    "                if top_k_preds.shape[1] >= 2 and target in top_k_preds[i, :2]:\n",
    "                    self.top2_correct += 1\n",
    "                if top_k_preds.shape[1] >= 3 and target in top_k_preds[i, :3]:\n",
    "                    self.top3_correct += 1\n",
    "    \n",
    "    def update_plate(self, predicted_plate, target_plate):\n",
    "        \"\"\"\n",
    "        Update plate-level metrics (WER).\n",
    "        \n",
    "        Args:\n",
    "            predicted_plate: String of predicted plate characters\n",
    "            target_plate: String of ground truth plate characters\n",
    "        \"\"\"\n",
    "        self.total_plates += 1\n",
    "        if predicted_plate == target_plate:\n",
    "            self.correct_plates += 1\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"Compute all metrics and return as dictionary.\"\"\"\n",
    "        if self.total_chars == 0:\n",
    "            return {}\n",
    "        \n",
    "        metrics = {\n",
    "            'CER': 1.0 - (self.correct_chars / self.total_chars),  # Character Error Rate\n",
    "            'char_accuracy': self.correct_chars / self.total_chars,\n",
    "            'top2_accuracy': self.top2_correct / self.total_chars if self.total_chars > 0 else 0.0,\n",
    "            'top3_accuracy': self.top3_correct / self.total_chars if self.total_chars > 0 else 0.0,\n",
    "            'similarity_aware_accuracy': self.similarity_score / self.total_chars,\n",
    "        }\n",
    "        \n",
    "        if self.total_plates > 0:\n",
    "            metrics['WER'] = 1.0 - (self.correct_plates / self.total_plates)  # Word Error Rate\n",
    "            metrics['plate_accuracy'] = self.correct_plates / self.total_plates\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "# Initialize OCR metrics tracker\n",
    "ocr_metrics = OCRMetrics(similarity_matrix=similarity_matrix)\n",
    "\n",
    "# Test metrics with dummy data\n",
    "test_preds = torch.tensor([CHAR_TO_IDX['O'], CHAR_TO_IDX['1'], CHAR_TO_IDX['A']])\n",
    "test_targets = torch.tensor([CHAR_TO_IDX['0'], CHAR_TO_IDX['I'], CHAR_TO_IDX['A']])\n",
    "test_topk = torch.tensor([\n",
    "    [CHAR_TO_IDX['O'], CHAR_TO_IDX['0']],\n",
    "    [CHAR_TO_IDX['1'], CHAR_TO_IDX['I']],\n",
    "    [CHAR_TO_IDX['A'], CHAR_TO_IDX['B']],\n",
    "])\n",
    "\n",
    "ocr_metrics.update(test_preds, test_targets, test_topk)\n",
    "test_metrics = ocr_metrics.compute()\n",
    "\n",
    "print('OCR Metrics Test Results:')\n",
    "for key, value in test_metrics.items():\n",
    "    print(f'  {key}: {value:.4f}')\n",
    "\n",
    "print('\\nOCR metrics module ready for validation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15722e6",
   "metadata": {},
   "source": [
    "### 6.2. Multi-Task Loss Weights\n",
    "\n",
    "**Logic:** The model performs three distinct tasks: segmentation (mask generation), localization (bounding boxes), and classification (character recognition). Default YOLO weighting may not be optimal for OCR, where classification accuracy is paramount. By explicitly balancing these losses (mask_weight=0.4, box_weight=0.3, cls_weight=0.3), we ensure the model doesn't over-prioritize segmentation quality at the expense of character recognition. These weights are tunable based on application needs—surveillance may prioritize localization, while data entry prioritizes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-task loss weights configuration\n",
    "MASK_WEIGHT = 0.4  # Segmentation mask loss weight\n",
    "BOX_WEIGHT = 0.3   # Bounding box loss weight  \n",
    "CLS_WEIGHT = 0.3   # Character classification loss weight\n",
    "\n",
    "print(f'Multi-task loss weights configured:')\n",
    "print(f'  Mask (segmentation): {MASK_WEIGHT:.1f}')\n",
    "print(f'  Box (localization): {BOX_WEIGHT:.1f}')\n",
    "print(f'  Class (recognition): {CLS_WEIGHT:.1f}')\n",
    "print(f'  Total: {MASK_WEIGHT + BOX_WEIGHT + CLS_WEIGHT:.1f}')\n",
    "\n",
    "print('\\nThese weights will be applied in the custom trainer to balance multi-task learning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fd9b7",
   "metadata": {},
   "source": [
    "## 6. Custom Segmentation Trainer with Enhanced Features\n",
    "\n",
    "Integrates all improvements: dynamic similarity matrix updates, temperature annealing, adaptive weighting, OCR metrics, and multi-task loss balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegmentationTrainer(SegmentationTrainer):\n",
    "    \"\"\"\n",
    "    Custom trainer with:\n",
    "    - Dynamic similarity matrix updates\n",
    "    - Temperature annealing\n",
    "    - Adaptive loss weighting\n",
    "    - OCR-specific metrics\n",
    "    - Multi-task loss balancing\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg=None, overrides=None, _callbacks=None):\n",
    "        super().__init__(cfg, overrides, _callbacks)\n",
    "        \n",
    "        # Initialize improved loss function\n",
    "        self.character_loss_fn = ImprovedSimilarityAwareTopKLoss(\n",
    "            num_classes=NUM_CLASSES,\n",
    "            similarity_matrix=dynamic_sim_matrix.get_similarity_matrix(),\n",
    "            k=2,\n",
    "            initial_temperature=1.0,\n",
    "            base_weight=0.7,\n",
    "            topk_weight=0.3,\n",
    "            epochs=EPOCHS\n",
    "        ).to(device)\n",
    "        \n",
    "        # Initialize OCR metrics tracker\n",
    "        self.ocr_metrics = OCRMetrics(similarity_matrix=similarity_matrix)\n",
    "        \n",
    "        # Multi-task loss weights\n",
    "        self.mask_weight = MASK_WEIGHT\n",
    "        self.box_weight = BOX_WEIGHT\n",
    "        self.cls_weight = CLS_WEIGHT\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        \"\"\"Called at the start of each training epoch.\"\"\"\n",
    "        super().on_train_epoch_start()\n",
    "        \n",
    "        # Update temperature in loss function\n",
    "        self.character_loss_fn.update_epoch(self.epoch)\n",
    "    \n",
    "    def on_val_start(self):\n",
    "        \"\"\"Called at the start of validation.\"\"\"\n",
    "        super().on_val_start()\n",
    "        self.ocr_metrics.reset()\n",
    "    \n",
    "    def on_val_end(self):\n",
    "        \"\"\"Called at the end of validation - update similarity matrix and log metrics.\"\"\"\n",
    "        super().on_val_end()\n",
    "        \n",
    "        # Update dynamic similarity matrix every 10 epochs\n",
    "        if self.epoch % 10 == 0 and self.epoch > 0:\n",
    "            new_similarity = dynamic_sim_matrix.update_similarity_matrix()\n",
    "            self.character_loss_fn.similarity_matrix = new_similarity.to(device)\n",
    "            print(f'[Epoch {self.epoch}] Similarity matrix updated from validation confusion patterns.')\n",
    "        \n",
    "        # Compute and log OCR metrics\n",
    "        ocr_results = self.ocr_metrics.compute()\n",
    "        if ocr_results:\n",
    "            print(f'\\n[Epoch {self.epoch}] OCR Metrics:')\n",
    "            for key, value in ocr_results.items():\n",
    "                print(f'  {key}: {value:.4f}')\n",
    "    \n",
    "    def compute_loss(self, preds, batch):\n",
    "        \"\"\"Compute multi-task loss with balanced weights.\"\"\"\n",
    "        # Get base YOLO losses (box, mask, class)\n",
    "        base_loss = super().compute_loss(preds, batch)\n",
    "        \n",
    "        # Apply multi-task weights to base loss components\n",
    "        # Note: This is a simplified approach. In practice, you'd decompose base_loss\n",
    "        # into its components and weight them individually\n",
    "        weighted_base_loss = base_loss * (self.mask_weight + self.box_weight) / 2\n",
    "        \n",
    "        # Add custom similarity-aware character classification loss\n",
    "        if len(preds) > 3:\n",
    "            cls_logits = preds[3]\n",
    "            cls_targets = batch['cls'].long()\n",
    "            \n",
    "            if cls_logits is not None and cls_targets is not None:\n",
    "                cls_logits_flat = cls_logits.view(-1, NUM_CLASSES)\n",
    "                cls_targets_flat = cls_targets.view(-1)\n",
    "                \n",
    "                valid_mask = cls_targets_flat >= 0\n",
    "                if valid_mask.sum() > 0:\n",
    "                    # Compute similarity-aware classification loss\n",
    "                    char_loss = self.character_loss_fn(\n",
    "                        cls_logits_flat[valid_mask],\n",
    "                        cls_targets_flat[valid_mask]\n",
    "                    )\n",
    "                    \n",
    "                    # Apply classification weight\n",
    "                    weighted_char_loss = self.cls_weight * char_loss\n",
    "                    \n",
    "                    # Update confusion matrix for dynamic similarity updates\n",
    "                    with torch.no_grad():\n",
    "                        preds_cls = cls_logits_flat[valid_mask].argmax(dim=1)\n",
    "                        dynamic_sim_matrix.update_confusion(\n",
    "                            preds_cls.cpu().numpy(),\n",
    "                            cls_targets_flat[valid_mask].cpu().numpy()\n",
    "                        )\n",
    "                        \n",
    "                        # Update OCR metrics\n",
    "                        top_k_preds = torch.topk(cls_logits_flat[valid_mask], k=3, dim=1)[1]\n",
    "                        self.ocr_metrics.update(\n",
    "                            preds_cls,\n",
    "                            cls_targets_flat[valid_mask],\n",
    "                            top_k_preds\n",
    "                        )\n",
    "                    \n",
    "                    # Combine losses\n",
    "                    total_loss = weighted_base_loss + weighted_char_loss\n",
    "                    return total_loss\n",
    "        \n",
    "        return weighted_base_loss\n",
    "\n",
    "print('Custom segmentation trainer with all improvements defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc7676",
   "metadata": {},
   "source": [
    "## 7. Training Configuration (Hyperparameters & Augmentations)\n",
    "\n",
    "Configure training hyperparameters tuned for character-level OCR on CCTV footage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ef3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "\n",
    "LR0 = 0.01\n",
    "LRF = 0.01\n",
    "MOMENTUM = 0.937\n",
    "WEIGHT_DECAY = 5e-4\n",
    "WARMUP_EPOCHS = 3.0\n",
    "WARMUP_MOMENTUM = 0.8\n",
    "WARMUP_BIAS_LR = 0.1\n",
    "\n",
    "AUG_HSV_H = 0.015\n",
    "AUG_HSV_S = 0.7\n",
    "AUG_HSV_V = 0.4\n",
    "AUG_ERASING = 0.4\n",
    "AUG_FLIPLR = 0.0\n",
    "AUG_MOSAIC = 0.0\n",
    "AUG_MIXUP = 0.0\n",
    "AUG_COPY_PASTE = 0.0\n",
    "\n",
    "print('Hyperparameters configured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32243a00",
   "metadata": {},
   "source": [
    "### 7.1. Hyperparameter and Augmentation Rationale\n",
    "\n",
    "These settings aim to balance robustness, stability, and efficiency for text-level OCR on pre‑augmented character crops. SGD with momentum and weight decay, combined with cosine‑annealed learning rate and brief warmup (LR0 = 0.01, LRF = 0.01, MOMENTUM = 0.937, WEIGHT_DECAY = 5e-4, WARMUP_EPOCHS = 3), follows recommended YOLO training practice and is known to improve convergence and final accuracy over simple step schedules in vision models. [https://docs.ultralytics.com/guides/hyperparameter-tuning/](https://docs.ultralytics.com/guides/hyperparameter-tuning/)\n",
    "\n",
    "Moderate HSV jitter and random erasing (AUG_HSV_*, AUG_ERASING = 0.4) extend lighting and occlusion variability to better match CCTV conditions while preserving character structure. [https://arxiv.org/abs/1902.07296](https://arxiv.org/abs/1902.07296)\n",
    "\n",
    "Horizontal flips and detection-style augmentations (Mosaic, MixUp, Copy-Paste) are disabled because mirrored or composited text does not occur in the target domain and can degrade OCR performance. [https://home.nr.no/~eikvil/OCR.pdf](https://home.nr.no/~eikvil/OCR.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091b6d6",
   "metadata": {},
   "source": [
    "## 8. Initialize Model and Attach Custom Trainer\n",
    "\n",
    "Load YOLO11-seg as the backbone and plug in the custom trainer with similarity-aware character loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-seg.pt')\n",
    "model.trainer = CustomSegmentationTrainer\n",
    "\n",
    "print('Segmentation model initialized with custom trainer.')\n",
    "print('Includes: temperature annealing, adaptive weighting, dynamic similarity updates, OCR metrics, and multi-task loss balancing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c395c73",
   "metadata": {},
   "source": [
    "## 9. Optional: Early Stopping Callback\n",
    "\n",
    "Halt training if validation loss stalls for a prolonged period to prevent overfitting and wasted compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "EARLY_STOP_PATIENCE = 50\n",
    "\n",
    "def early_stopping_callback(trainer):\n",
    "    global best_val_loss, no_improve_epochs\n",
    "    metrics = trainer.metrics or {}\n",
    "    val_loss = metrics.get('loss', None)\n",
    "    if val_loss is None:\n",
    "        return\n",
    "\n",
    "    if best_val_loss == float('inf'):\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "        return\n",
    "\n",
    "    improvement = (best_val_loss - val_loss) / max(best_val_loss, 1e-8) * 100.0\n",
    "    if improvement >= 1.0:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= EARLY_STOP_PATIENCE:\n",
    "        print(f'Early stopping at epoch {trainer.epoch}')\n",
    "        trainer.stop = True\n",
    "\n",
    "model.add_callback('on_val_end', early_stopping_callback)\n",
    "print('Early stopping callback registered.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bd529",
   "metadata": {},
   "source": [
    "## 10. Train Segmentation Model with Similarity-Aware Character Loss\n",
    "\n",
    "Train YOLO11-seg on polygon annotations with the custom trainer. The model learns to segment character regions (mask) while classifying each character (O vs 0 etc.) with reduced penalties for visually similar confusions. Make sure `DATA_YAML_PATH` points to your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2731dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=DATA_YAML_PATH,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    optimizer='SGD',\n",
    "    lr0=LR0,\n",
    "    lrf=LRF,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_epochs=WARMUP_EPOCHS,\n",
    "    warmup_momentum=WARMUP_MOMENTUM,\n",
    "    warmup_bias_lr=WARMUP_BIAS_LR,\n",
    "    hsv_h=AUG_HSV_H,\n",
    "    hsv_s=AUG_HSV_S,\n",
    "    hsv_v=AUG_HSV_V,\n",
    "    erasing=AUG_ERASING,\n",
    "    fliplr=AUG_FLIPLR,\n",
    "    mosaic=AUG_MOSAIC,\n",
    "    mixup=AUG_MIXUP,\n",
    "    copy_paste=AUG_COPY_PASTE,\n",
    "    project=RUN_PROJECT,\n",
    "    name=RUN_NAME,\n",
    "    exist_ok=True,\n",
    "    val=True,\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    amp=True,\n",
    "    device=0 if device == 'cuda' else 'cpu',\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "print('Training completed.')\n",
    "print('Results directory:', results.save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff953db",
   "metadata": {},
   "source": [
    "## 11. Export Best Model\n",
    "\n",
    "Copy the best weights to the export directory for inference and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "best_weights_path = os.path.join(str(results.save_dir), 'weights', 'best.pt')\n",
    "export_path = os.path.join(EXPORT_DIR, f'{RUN_NAME}_best.pt')\n",
    "\n",
    "if os.path.exists(best_weights_path):\n",
    "    shutil.copy2(best_weights_path, export_path)\n",
    "    print('Best weights exported to:', export_path)\n",
    "else:\n",
    "    print('best.pt not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb92b2",
   "metadata": {},
   "source": [
    "## 12. Inference on Test Images\n",
    "\n",
    "Load the trained model and run inference to validate segmentation and character classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = YOLO(export_path if os.path.exists(export_path) else best_weights_path)\n",
    "\n",
    "TEST_IMAGE_PATHS = [\n",
    "    # '/content/test_plate_1.jpg',\n",
    "    # '/content/test_plate_2.jpg',\n",
    "]\n",
    "\n",
    "for img_path in TEST_IMAGE_PATHS:\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f'Test image not found: {img_path}')\n",
    "        continue\n",
    "    \n",
    "    results_inf = inference_model(img_path, imgsz=IMG_SIZE)\n",
    "    print(f'\\nInference on {img_path}')\n",
    "    for r in results_inf:\n",
    "        if r.masks is not None:\n",
    "            print(f'Detected {len(r.masks)} character instances')\n",
    "        if r.boxes is not None:\n",
    "            print(f'Boxes: {r.boxes.cls}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
