{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f6d1e2",
   "metadata": {},
   "source": [
    "# Philippine License Plate Character Instance Segmentation with Similarity-Aware Loss\n",
    "\n",
    "Single-stage training: YOLO11-seg with polygon masks and character labels, using a custom similarity-aware loss function to handle visually confusable characters (O/0, I/1/L, etc.) in CCTV surveillance footage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79720b9a",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "This notebook is optimized for Google Colab with a T4 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U ultralytics --quiet\n",
    "\n",
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be0f6b",
   "metadata": {},
   "source": [
    "## 1. Paths and Configuration Variables\n",
    "\n",
    "Set these to your actual dataset and output locations before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f34f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML_PATH = '/content/philippine_lp_chars.yaml'\n",
    "RUN_PROJECT = 'philippine_lp_ocr'\n",
    "RUN_NAME = 'seg_with_similarity_loss'\n",
    "EXPORT_DIR = '/content/exports'\n",
    "\n",
    "!mkdir -p \"$EXPORT_DIR\"\n",
    "print('DATA_YAML_PATH:', DATA_YAML_PATH)\n",
    "print('EXPORT_DIR:', EXPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891aee20",
   "metadata": {},
   "source": [
    "## 2. Imports\n",
    "\n",
    "Core dependencies for segmentation training, custom loss, and optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.segment import SegmentationTrainer\n",
    "from ultralytics.nn.tasks import SegmentationModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144851a",
   "metadata": {},
   "source": [
    "## 3. Character Set and Similarity Matrix\n",
    "\n",
    "Define the 36-class character set (A–Z, 0–9) and visual-similarity relationships based on glyph shapes. Characters in the same group (e.g., O, 0, Q) are visually similar and should receive reduced penalties when confused during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = [chr(i) for i in range(65, 91)] + [str(i) for i in range(10)]\n",
    "NUM_CLASSES = len(CHARS)\n",
    "CHAR_TO_IDX = {c: i for i, c in enumerate(CHARS)}\n",
    "IDX_TO_CHAR = {i: c for i, c in enumerate(CHARS)}\n",
    "\n",
    "print('Number of classes:', NUM_CLASSES)\n",
    "print('Characters:', CHARS)\n",
    "\n",
    "SIMILAR_GROUPS = [\n",
    "    ['O', '0', 'Q'],\n",
    "    ['I', '1', 'L'],\n",
    "    ['S', '5'],\n",
    "    ['Z', '2'],\n",
    "    ['B', '8'],\n",
    "    ['D', '0'],\n",
    "    ['G', 'C'],\n",
    "    ['U', 'V'],\n",
    "    ['P', 'R'],\n",
    "]\n",
    "\n",
    "def create_similarity_matrix(num_classes=NUM_CLASSES, groups=SIMILAR_GROUPS, base_sim=0.6):\n",
    "    S = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    for group in groups:\n",
    "        idxs = [CHAR_TO_IDX[c] for c in group if c in CHAR_TO_IDX]\n",
    "        for i in idxs:\n",
    "            for j in idxs:\n",
    "                if i != j:\n",
    "                    S[i, j] = base_sim\n",
    "    return torch.tensor(S, dtype=torch.float32)\n",
    "\n",
    "similarity_matrix = create_similarity_matrix()\n",
    "print('Similarity matrix shape:', similarity_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d38971",
   "metadata": {},
   "source": [
    "## 4. Custom Similarity-Aware Loss Function\n",
    "\n",
    "Similarity-aware top-k loss directly rewards the model when visually similar characters appear in the top-2 predictions. If the model is uncertain between O and 0, having both in the top-2 with high confidence is acceptable and should be penalized less than confidently predicting X when the answer is O. This matches the requirement of considering \"top-K outputs (e.g., top-2) rather than only the single best prediction.\" [https://openaccess.thecvf.com/content_cvpr_2016/papers/Lapin_Loss_Functions_for_CVPR_2016_paper.pdf](https://openaccess.thecvf.com/content_cvpr_2016/papers/Lapin_Loss_Functions_for_CVPR_2016_paper.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityAwareTopKLoss(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, similarity_matrix=None,\n",
    "                 k=2, temperature=1.0, base_weight=0.7, topk_weight=0.3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "        self.base_weight = base_weight\n",
    "        self.topk_weight = topk_weight\n",
    "        if similarity_matrix is not None:\n",
    "            self.register_buffer('similarity_matrix', similarity_matrix)\n",
    "        else:\n",
    "            self.register_buffer('similarity_matrix', create_similarity_matrix())\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        B = logits.size(0)\n",
    "        device = logits.device\n",
    "\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        probs = F.softmax(logits / self.temperature, dim=1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, self.k, dim=1)\n",
    "\n",
    "        sim_loss = torch.zeros(B, device=device)\n",
    "        for i in range(B):\n",
    "            t = targets[i].item()\n",
    "            sims = self.similarity_matrix[t][topk_indices[i]]\n",
    "            penalties = 1.0 - sims\n",
    "            weighted_penalties = topk_probs[i] * penalties\n",
    "            sim_loss[i] = weighted_penalties.sum()\n",
    "\n",
    "        total = self.base_weight * ce_loss + self.topk_weight * sim_loss\n",
    "        return total.mean()\n",
    "\n",
    "print('Similarity-aware loss defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79036a",
   "metadata": {},
   "source": [
    "## 5. Sanity Check for Custom Loss\n",
    "\n",
    "Verify that confusing similar characters (O vs 0) incurs lower penalty than confusing very different characters (O vs X).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SimilarityAwareTopKLoss(num_classes=NUM_CLASSES, similarity_matrix=similarity_matrix, k=2).to(device)\n",
    "\n",
    "logits_similar = torch.zeros(1, NUM_CLASSES, device=device)\n",
    "logits_similar[0, CHAR_TO_IDX['0']] = 5.0\n",
    "target_O = torch.tensor([CHAR_TO_IDX['O']], device=device)\n",
    "loss_similar = loss_fn(logits_similar, target_O)\n",
    "\n",
    "logits_diff = torch.zeros(1, NUM_CLASSES, device=device)\n",
    "logits_diff[0, CHAR_TO_IDX['X']] = 5.0\n",
    "loss_diff = loss_fn(logits_diff, target_O)\n",
    "\n",
    "print(f'Loss (O vs 0): {loss_similar.item():.4f}')\n",
    "print(f'Loss (O vs X): {loss_diff.item():.4f}')\n",
    "assert loss_similar < loss_diff, 'Expected O/0 confusion < O/X confusion'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06f195",
   "metadata": {},
   "source": [
    "## 6. Custom Segmentation Trainer with Similarity-Aware Character Loss\n",
    "\n",
    "Override YOLO's segmentation trainer to inject the similarity-aware loss into the character classification head. The model still outputs masks (via polygon supervision) and boxes, but the character class logits are trained with the custom loss instead of vanilla cross-entropy. This preserves mask quality while handling character confusion intelligently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSegmentationTrainer(SegmentationTrainer):\n",
    "    def __init__(self, cfg=None, overrides=None, _callbacks=None):\n",
    "        super().__init__(cfg, overrides, _callbacks)\n",
    "        self.character_loss_fn = SimilarityAwareTopKLoss(\n",
    "            num_classes=NUM_CLASSES,\n",
    "            similarity_matrix=similarity_matrix,\n",
    "            k=2,\n",
    "            base_weight=0.7,\n",
    "            topk_weight=0.3,\n",
    "        ).to(device)\n",
    "    \n",
    "    def compute_loss(self, preds, batch):\n",
    "        base_loss = super().compute_loss(preds, batch)\n",
    "        \n",
    "        if len(preds) > 3:\n",
    "            cls_logits = preds[3]\n",
    "            cls_targets = batch['cls'].long()\n",
    "            \n",
    "            if cls_logits is not None and cls_targets is not None:\n",
    "                cls_logits_flat = cls_logits.view(-1, NUM_CLASSES)\n",
    "                cls_targets_flat = cls_targets.view(-1)\n",
    "                \n",
    "                valid_mask = cls_targets_flat >= 0\n",
    "                if valid_mask.sum() > 0:\n",
    "                    char_loss = self.character_loss_fn(\n",
    "                        cls_logits_flat[valid_mask],\n",
    "                        cls_targets_flat[valid_mask]\n",
    "                    )\n",
    "                    base_loss += 0.5 * char_loss\n",
    "        \n",
    "        return base_loss\n",
    "\n",
    "print('Custom segmentation trainer defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc7676",
   "metadata": {},
   "source": [
    "## 7. Training Configuration (Hyperparameters & Augmentations)\n",
    "\n",
    "Configure training hyperparameters tuned for character-level OCR on CCTV footage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ef3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "\n",
    "LR0 = 0.01\n",
    "LRF = 0.01\n",
    "MOMENTUM = 0.937\n",
    "WEIGHT_DECAY = 5e-4\n",
    "WARMUP_EPOCHS = 3.0\n",
    "WARMUP_MOMENTUM = 0.8\n",
    "WARMUP_BIAS_LR = 0.1\n",
    "\n",
    "AUG_HSV_H = 0.015\n",
    "AUG_HSV_S = 0.7\n",
    "AUG_HSV_V = 0.4\n",
    "AUG_ERASING = 0.4\n",
    "AUG_FLIPLR = 0.0\n",
    "AUG_MOSAIC = 0.0\n",
    "AUG_MIXUP = 0.0\n",
    "AUG_COPY_PASTE = 0.0\n",
    "\n",
    "print('Hyperparameters configured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32243a00",
   "metadata": {},
   "source": [
    "### 7.1. Hyperparameter and Augmentation Rationale\n",
    "\n",
    "These settings aim to balance robustness, stability, and efficiency for text-level OCR on pre‑augmented character crops. SGD with momentum and weight decay, combined with cosine‑annealed learning rate and brief warmup (LR0 = 0.01, LRF = 0.01, MOMENTUM = 0.937, WEIGHT_DECAY = 5e-4, WARMUP_EPOCHS = 3), follows recommended YOLO training practice and is known to improve convergence and final accuracy over simple step schedules in vision models. [https://docs.ultralytics.com/guides/hyperparameter-tuning/](https://docs.ultralytics.com/guides/hyperparameter-tuning/)\n",
    "\n",
    "Moderate HSV jitter and random erasing (AUG_HSV_*, AUG_ERASING = 0.4) extend lighting and occlusion variability to better match CCTV conditions while preserving character structure. [https://arxiv.org/abs/1902.07296](https://arxiv.org/abs/1902.07296)\n",
    "\n",
    "Horizontal flips and detection-style augmentations (Mosaic, MixUp, Copy-Paste) are disabled because mirrored or composited text does not occur in the target domain and can degrade OCR performance. [https://home.nr.no/~eikvil/OCR.pdf](https://home.nr.no/~eikvil/OCR.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091b6d6",
   "metadata": {},
   "source": [
    "## 8. Initialize Model and Attach Custom Trainer\n",
    "\n",
    "Load YOLO11-seg as the backbone and plug in the custom trainer with similarity-aware character loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-seg.pt')\n",
    "model.trainer = CustomSegmentationTrainer\n",
    "\n",
    "print('Segmentation model initialized with custom trainer.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c395c73",
   "metadata": {},
   "source": [
    "## 9. Optional: Early Stopping Callback\n",
    "\n",
    "Halt training if validation loss stalls for a prolonged period to prevent overfitting and wasted compute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "EARLY_STOP_PATIENCE = 50\n",
    "\n",
    "def early_stopping_callback(trainer):\n",
    "    global best_val_loss, no_improve_epochs\n",
    "    metrics = trainer.metrics or {}\n",
    "    val_loss = metrics.get('loss', None)\n",
    "    if val_loss is None:\n",
    "        return\n",
    "\n",
    "    if best_val_loss == float('inf'):\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "        return\n",
    "\n",
    "    improvement = (best_val_loss - val_loss) / max(best_val_loss, 1e-8) * 100.0\n",
    "    if improvement >= 1.0:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= EARLY_STOP_PATIENCE:\n",
    "        print(f'Early stopping at epoch {trainer.epoch}')\n",
    "        trainer.stop = True\n",
    "\n",
    "model.add_callback('on_val_end', early_stopping_callback)\n",
    "print('Early stopping callback registered.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376bd529",
   "metadata": {},
   "source": [
    "## 10. Train Segmentation Model with Similarity-Aware Character Loss\n",
    "\n",
    "Train YOLO11-seg on polygon annotations with the custom trainer. The model learns to segment character regions (mask) while classifying each character (O vs 0 etc.) with reduced penalties for visually similar confusions. Make sure `DATA_YAML_PATH` points to your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2731dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data=DATA_YAML_PATH,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    optimizer='SGD',\n",
    "    lr0=LR0,\n",
    "    lrf=LRF,\n",
    "    momentum=MOMENTUM,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_epochs=WARMUP_EPOCHS,\n",
    "    warmup_momentum=WARMUP_MOMENTUM,\n",
    "    warmup_bias_lr=WARMUP_BIAS_LR,\n",
    "    hsv_h=AUG_HSV_H,\n",
    "    hsv_s=AUG_HSV_S,\n",
    "    hsv_v=AUG_HSV_V,\n",
    "    erasing=AUG_ERASING,\n",
    "    fliplr=AUG_FLIPLR,\n",
    "    mosaic=AUG_MOSAIC,\n",
    "    mixup=AUG_MIXUP,\n",
    "    copy_paste=AUG_COPY_PASTE,\n",
    "    project=RUN_PROJECT,\n",
    "    name=RUN_NAME,\n",
    "    exist_ok=True,\n",
    "    val=True,\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    amp=True,\n",
    "    device=0 if device == 'cuda' else 'cpu',\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "print('Training completed.')\n",
    "print('Results directory:', results.save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff953db",
   "metadata": {},
   "source": [
    "## 11. Export Best Model\n",
    "\n",
    "Copy the best weights to the export directory for inference and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "best_weights_path = os.path.join(str(results.save_dir), 'weights', 'best.pt')\n",
    "export_path = os.path.join(EXPORT_DIR, f'{RUN_NAME}_best.pt')\n",
    "\n",
    "if os.path.exists(best_weights_path):\n",
    "    shutil.copy2(best_weights_path, export_path)\n",
    "    print('Best weights exported to:', export_path)\n",
    "else:\n",
    "    print('best.pt not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb92b2",
   "metadata": {},
   "source": [
    "## 12. Inference on Test Images\n",
    "\n",
    "Load the trained model and run inference to validate segmentation and character classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = YOLO(export_path if os.path.exists(export_path) else best_weights_path)\n",
    "\n",
    "TEST_IMAGE_PATHS = [\n",
    "    # '/content/test_plate_1.jpg',\n",
    "    # '/content/test_plate_2.jpg',\n",
    "]\n",
    "\n",
    "for img_path in TEST_IMAGE_PATHS:\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f'Test image not found: {img_path}')\n",
    "        continue\n",
    "    \n",
    "    results_inf = inference_model(img_path, imgsz=IMG_SIZE)\n",
    "    print(f'\\nInference on {img_path}')\n",
    "    for r in results_inf:\n",
    "        if r.masks is not None:\n",
    "            print(f'Detected {len(r.masks)} character instances')\n",
    "        if r.boxes is not None:\n",
    "            print(f'Boxes: {r.boxes.cls}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
